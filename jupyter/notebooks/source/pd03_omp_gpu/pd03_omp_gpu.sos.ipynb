{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-001",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#  OpenMP for GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-002",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "Enter your name and student ID.\n",
        "\n",
        " * Name:\n",
        " * Student ID:\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-003",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 1. OpenMP for GPU",
        "\n",
        "* <a href=\"http://openmp.org/\" target=\"_blank\" rel=\"noopener\">OpenMP</a> is the de fact programming model for multicore environment\n",
        "* More recently, it supports GPU offloading\n",
        "* In this notebook you are going to learn OpenMP for GPU\n",
        "* Consult [the spec](https://www.openmp.org/spec-html/5.0/openmp.html) when necessary\n",
        "* Take a look at [a talk slide OPENMP IN NVIDIA'S HPC by Jeff Larkin](https://openmpcon.org/wp-content/uploads/openmpcon2021-nvidia.pdf)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-004",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 2. Compilers",
        "\n",
        "* [NVIDIA HPC SDK](https://docs.nvidia.com/hpc-sdk/index.html) (`nvc` and `nvc++`) and recent [LLVM](https://llvm.org/) (`clang` and `clang++`) have a decent support of OpenMP for GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-005",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-1. Set up NVIDIA HPC SDK",
        "\n",
        "Execute this before you use NVIDIA HPC SDK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-006",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/24.9/compilers/bin:$PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-007",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Check if it works (check if full paths of nvc/nvc++ are shown)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-008",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which nvc\n",
        "which nvc++"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-009",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-2. Set up LLVM",
        "\n",
        "Execute this before you use LLVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-010",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/home/share/llvm/bin:$PATH\n",
        "export LD_LIBRARY_PATH=/home/share/llvm/lib:/home/share/llvm/lib/x86_64-unknown-linux-gnu:$LD_LIBRARY_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-011",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Check if it works (check if full paths of nvc/nvc++ are shown)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-012",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which clang\n",
        "which clang++"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-013",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Compilers can work at any host, but make sure you are on the GPU host before running GPU programs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-014",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "hostname\n",
        "hostname | grep tauleg || echo \"Oh, you are not on the right host, access https://tauleg.zapto.org/ instead\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-015",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-3. Summary of compiler options to compile OpenMP programs for GPU",
        "\n",
        "* `nvc`/`nvc++` : `-mp=gpu` option\n",
        "* `clang`/`clang++` : `-fopenmp -fopenmp-targets=nvptx64` options"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-016",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 3. Summary of directives you are going to learn",
        "\n",
        "* [`#pragma omp target`](https://www.openmp.org/spec-html/5.0/openmpsu60.html#x86-2820002.12.5) : offloads the immediately following statement to the device\n",
        "* [`#pragma omp teams`](https://www.openmp.org/spec-html/5.0/openmpse15.html#x57-910002.7) : creates a number of teams (similar to `#pragma omp parallel`)\n",
        "* [`#pragma omp distribute`](https://www.openmp.org/spec-html/5.0/openmpsu43.html#x66-1580002.9.4) : distributes iterations of the immediately following for loop to teams\n",
        "* [`#pragma omp parallel`](https://www.openmp.org/spec-html/5.0/openmpse14.html#x54-800002.6) : creates a number of threads within a team\n",
        "* [`#pragma omp for`](https://www.openmp.org/spec-html/5.0/openmpsu41.html#x64-1290002.9.2) : distributes iterations of the immediately following for loop to threads of a team\n",
        "* [`#pragma omp target data`](https://www.openmp.org/spec-html/5.0/openmpsu57.html#x83-2580002.12.2)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 4. [`#pragma omp target`](https://www.openmp.org/spec-html/5.0/openmpsu60.html) $\\sim$ moving control to a GPU",
        "\n",
        "* <font color=\"blue\">syntax</font>\n",
        "```\n",
        "#pragma omp target\n",
        "    S\n",
        "```\n",
        "executes $S$ on (_offloads_ $S$ to) a device (hopefully a GPU)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-018",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_target.cc\n",
        "#include <stdio.h>\n",
        "int main() {\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "  printf(\"hello from target (hopefully GPU)\\n\");\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-019",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-020",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp -target=gpu omp_target.cc -o omp_target\n",
        "# clang++ -fopenmp -fopenmp-targets=nvptx64 omp_target.cc -o omp_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-021",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-022",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-023",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * while using `target` almost always intends to use a GPU, it can actually run without a GPU (fallback)\n",
        "  * executing the above program results in an identical result whether your machine has a GPU or not\n",
        "  * while good for portability, it may be confusing, so you can force it to run on GPU or signal an error when GPU is not available, by setting environment variable `OMP_TARGET_OFFLOAD=MANDATORY`.  `OMP_TARGET_OFFLOAD=DISABLED` has the opposite effect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-024",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# force it to run on GPU or signal an error\n",
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_target\n",
        "# force it to run on the host even if GPU is available\n",
        "OMP_TARGET_OFFLOAD=DISABLED ./omp_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-025",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 5. [`#pragma omp teams`](https://www.openmp.org/spec-html/5.0/openmpse15.html#x57-910002.7) $\\sim$ creating thread blocks",
        "\n",
        "## 5-1. basics",
        "\n",
        "* <font color=\"blue\">syntax</font>\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    S\n",
        "```\n",
        "creates a number of _teams_ and the master of each team will execute $S$\n",
        "\n",
        "* it is similar to `#pragma omp parallel` in the sense that the effect is to have many threads execute the same statement\n",
        "* you can think of `teams` an extra layer of parallelism outside `parallel` (`parallel` is a construct that creates threads _within_ a team)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-026",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_teams.cc\n",
        "#include <stdio.h>\n",
        "int main() {\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "  printf(\"hello, I am the master of a team\\n\");\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-027",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_teams.cc -o omp_teams\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_teams.cc -o omp_teams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-028",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-029",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_teams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-030",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * `teams` should appear right inside `target`\n",
        "  * as such, `target` and `teams` are often used in the combined form (`#pragma omp target teams`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-031",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 5-2. specifying the number of teams",
        "\n",
        "* you can set the number of teams created by `teams` construct to $x$ either by\n",
        "  * having `num_teams(x)` clause in the `teams` construct\n",
        "  * setting `OMP_NUM_TEAMS=x` environment variable when running the command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-032",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 ./omp_teams\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=5 ./omp_teams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-033",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 5-3. getting team ID and the number of teams",
        "\n",
        "* just as `omp_get_thread_num()` and `omp_get_num_threads()` tell you the thread ID and the number of threads of your team, you can get the team ID and the number of teams by\n",
        "* `omp_get_num_teams()` \n",
        "  * `omp_get_team_num()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-034",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_team_num.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main() {\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "  printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-035",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_team_num.cc -o omp_team_num\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_team_num.cc -o omp_team_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-036",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-037",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=5 ./omp_team_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-038",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 6. [`#pragma omp distribute`](https://www.openmp.org/spec-html/5.0/openmpsu43.html#x66-1580002.9.4) $\\sim$ distributing iterations to thread blocks",
        "\n",
        "* <font color=\"blue\">syntax</font>\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    {\n",
        "      ...\n",
        "#pragma omp distribute\n",
        "      for (...) {\n",
        "        ...\n",
        "      }\n",
        "    }\n",
        "```\n",
        "distributes iterations of the for-loop across teams\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-039",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_distribute.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5); i++;\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp distribute\n",
        "    for (int i = 0; i < m; i++) {\n",
        "      printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams());\n",
        "    }\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-040",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_distribute.cc -o omp_distribute\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_distribute.cc -o omp_distribute"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-001",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 ./omp_distribute 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-041",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* execute the following command with different number of teams and the command line (the number of iterations) and make sense of the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-042",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 1 :  Understand teams and distribute</font>",
        "\n",
        "* a small quiz before things get more confusing\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ ./omp_distribute $m$</tt></font>\n",
        "* answer with an expression of $T$ and $m$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-002",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 ./omp_distribute 5 | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-003",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-043",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* execute the following command with different number of teams and the command line (the number of iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-044",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * if there is no statements between `teams` and `distribute` they can be combined into one directive, just as * recall that `target` can be combined with `teams`, so you can combine all the three \n",
        "`parallel` and `for` can be combined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-045",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_target_teams_distribute.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5);\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams distribute\n",
        "  for (int i = 0; i < m; i++) {\n",
        "    printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "           i, omp_get_team_num(), omp_get_num_teams());\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-046",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_target_teams_distribute.cc -o omp_target_teams_distribute\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_target_teams_distribute.cc -o omp_target_teams_distribute"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-047",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 ./omp_target_teams_distribute 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-048",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * you can parallelize a loop with just `teams` and `distribute` without `parallel` and `for` described below\n",
        "  * however, to effectively use GPUs, you need to use `parallel` within each team\n",
        "  * while implementation dependent, you can think of a team as a single thread block, so only using teams, you end up creating many thread blocks each having only a single thread, resulting in very inefficient use of GPUs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-049",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 7. [`#pragma omp parallel`](https://www.openmp.org/spec-html/5.0/openmpse14.html#x54-800002.6) $\\sim$ having threads in a thread block",
        "\n",
        "## 7-1. `parallel` inside `teams`",
        "\n",
        "* syntax:\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    {\n",
        "      ...\n",
        "#pragma omp parallel\n",
        "      S\n",
        "    }\n",
        "```\n",
        "creates a number of thread within each team\n",
        "\n",
        "* recall that you used `parallel` to create threads when executing on CPUs\n",
        "* used inside `teams`, it will create threads within the team, each executing $S$\n",
        "\n",
        "* here is an example that illustrates it\n",
        "<font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_team_parallel</tt></font>\n",
        "creates $T$ teams each of which create $H$ threads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-050",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_parallel.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int getenv_int(const char * v) {\n",
        "  char * s = getenv(v);\n",
        "  if (!s) {\n",
        "    fprintf(stderr, \"specify environment variable %s\\n\", v);\n",
        "    exit(1);\n",
        "  }\n",
        "  return atoi(s);\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n_threads= getenv_int(\"OMP_NUM_THREADS\");\n",
        "  if (n_threads != 1 && n_threads % 32) {\n",
        "    fprintf(stderr, \"OMP_NUM_THREADS (%d) must be 1 or a multiple of 32\\n\", n_threads);\n",
        "    exit(1);\n",
        "  }\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp parallel num_threads(n_threads)\n",
        "    printf(\"in parallel: %03d/%03d %03d/%03d\\n\",\n",
        "           omp_get_team_num(), omp_get_num_teams(),\n",
        "           omp_get_thread_num(), omp_get_num_threads());\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-051",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_parallel.cc -o omp_parallel\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_parallel.cc -o omp_parallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-052",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_parallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-053",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "* <font color=\"red\">important remarks on the number of threads you specify in `parallel` directive</font>\n",
        "  * on CPU, the number of threads created by `parallel` could be specified either with `OMP_NUM_THREADS=x` environment variable or `num_threads(x)` in `parallel` directive\n",
        "  * but this seems not possible when executing on GPUs (I don't know whether it is an implementation issue or specification)\n",
        "  * you have to use `num_threads(x)` if you need to set it, just as done above\n",
        "  * or you can just omit it to leave it to the system\n",
        "* also, it seems that with both clang and nvc, <font color=red>_the number of threads must be 1 or a multiple of 32_</font>\n",
        "  * it does not even signal an error, so you must be careful not to unintentionally specify a wrong number\n",
        "  * this is another reason to leave it to the system unless necessary\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-054",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 2 :  Understand teams and parallel</font>",
        "\n",
        "* a similar quiz about the combination of teams and parallel\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_parallel</tt></font>\n",
        "* answer with an expression of $T$ and $H$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-004",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_parallel | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-005",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-055",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 7-2. `parallel` inside `distribute` inside `teams`",
        "\n",
        "* more typically you call `parallel` inside `distribute` (which is necessarily inside `teams`), as you will be parallelizing loops\n",
        "* there is nothing new syntactically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-056",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_distribute_parallel.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int getenv_int(const char * v) {\n",
        "  char * s = getenv(v);\n",
        "  if (!s) {\n",
        "    fprintf(stderr, \"specify environment variable %s\\n\", v);\n",
        "    exit(1);\n",
        "  }\n",
        "  return atoi(s);\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n_threads= getenv_int(\"OMP_NUM_THREADS\");\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5); i++;\n",
        "  if (n_threads != 1 && n_threads % 32) {\n",
        "    fprintf(stderr, \"OMP_NUM_THREADS (%d) must be 1 or a multiple of 32\\n\", n_threads);\n",
        "    exit(1);\n",
        "  }\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp distribute\n",
        "    for (int i = 0; i < m; i++) {\n",
        "      printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp parallel num_threads(n_threads)\n",
        "      printf(\"in parallel: i=%03d %03d/%03d %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams(),\n",
        "             omp_get_thread_num(), omp_get_num_threads());\n",
        "    }\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-057",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_distribute_parallel.cc -o omp_distribute_parallel\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_distribute_parallel.cc -o omp_distribute_parallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-058",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_distribute_parallel 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-059",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 3 :  Understand teams, distribute, and parallel</font>",
        "\n",
        "* a similar quiz about the combination of teams, distribute, and parallel\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_distribute_parallel $m$</tt></font>\n",
        "* answer with an expression of $T$, $H$, and $m$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-006",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_distribute_parallel 5 | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-007",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-060",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 8. [`#pragma omp for`](https://www.openmp.org/spec-html/5.0/openmpsu41.html#x64-1290002.9.2) $\\sim$ distributing iterations to threads within a thread block",
        "\n",
        "* syntax:\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    ...\n",
        "#pragma omp distribute\n",
        "#pragma omp parallel\n",
        "    ...\n",
        "#pragma omp for\n",
        "for (...) {\n",
        "    ...\n",
        "}  \n",
        "```\n",
        "\n",
        "* used inside `parallel`, it will distribute iterations of the loop to threads\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-061",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_for.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int getenv_int(const char * v) {\n",
        "  char * s = getenv(v);\n",
        "  if (!s) {\n",
        "    fprintf(stderr, \"specify environment variable %s\\n\", v);\n",
        "    exit(1);\n",
        "  }\n",
        "  return atoi(s);\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n_threads = getenv_int(\"OMP_NUM_THREADS\");\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5); i++;\n",
        "  int n = (argc > i ? atoi(argv[i]) : 6); i++;\n",
        "  if (n_threads != 1 && n_threads % 32) {\n",
        "    fprintf(stderr, \"OMP_NUM_THREADS (%d) must be 1 or a multiple of 32\\n\", n_threads);\n",
        "    exit(1);\n",
        "  }\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp distribute\n",
        "    for (int i = 0; i < m; i++) {\n",
        "      printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp parallel num_threads(n_threads)\n",
        "      printf(\"in parallel: i=%03d %03d/%03d %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams(),\n",
        "             omp_get_thread_num(), omp_get_num_threads());\n",
        "#pragma omp for\n",
        "      for (int j = 0; j < n; j++) {\n",
        "        printf(\"in for: i=%03d j=%03d executed by %03d/%03d %03d/%03d\\n\",\n",
        "               i, j, omp_get_team_num(), omp_get_num_teams(),\n",
        "               omp_get_thread_num(), omp_get_num_threads());\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-062",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_for.cc -o omp_for\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_for.cc -o omp_for"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-063",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_for 5 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-064",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 4 :  Understand teams, distribute, parallel, and for</font>",
        "\n",
        "* a similar quiz about the combination of teams, distribute, parallel, and for\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_for $m$ $n$</tt></font>\n",
        "* answer with an expression of $T$, $H$, $m$, and $n$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-008",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_for 5 6 | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-009",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-065",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 9. Common combined directives",
        "\n",
        "* anybody who has a right mind will feel sick with the whole series of different directive names that have little or no consistency\n",
        "* each of them is nominally an independent, standalone directive, but many of them are almost always used together in practice\n",
        "* since the purpose is often to execute a loop nest in parallel, most typically they are used in one of the following forms\n",
        "\n",
        "* combine everything \n",
        "```\n",
        "#pragma omp target teams distribute parallel for\n",
        "    for (...) {\n",
        "      ...\n",
        "    }\n",
        "```\n",
        "\n",
        "* parallelize an outer loop with `teams` $+$ `distribute` and an inner loop with `parallel` $+$ `for`\n",
        "\n",
        "```\n",
        "#pragma omp target teams distribute\n",
        "    for (...) {\n",
        "#pragma omp parallel for\n",
        "      for (...) {\n",
        "        ...\n",
        "      }\n",
        "    }  \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-066",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 10. [`#pragma omp target data`](https://www.openmp.org/spec-html/5.0/openmpsu57.html#x83-2580002.12.2) $\\sim$ mapping data between the host CPU and GPU",
        "\n",
        "* in the CUDA programming, the only data transfer that more or less automatically occurs is passing call-by-value arguments (scalars and structures)\n",
        "* arrays and data pointed to by pointers must all be explicitly (1) allocated on GPU memory by `cudaMalloc` and (2) moved between CPU and GPU by `cudaMemcpy`, which quickly becomes tedious and error-prone\n",
        "* what we are conceptually doing when programming in CUDA is to maintain the mapping between data address on CPU and corresponding data address on GPU and synchronize their contents (data in that address) when necessary\n",
        "```\n",
        "a = malloc(...); // data on CPU @ a\n",
        "cudaMalloc(&a_dev, ...); // data on GPU @ a_dev\n",
        "cudaMemcpy(a_dev, a, ...); // move contents a[..] -> a_dev[..]\n",
        "  ...\n",
        "cudaMemcpy(a, a_dev, ...); // move contents a[..] <- a_dev[..]\n",
        "```\n",
        "\n",
        "* `target data` and its `map` clauses make it possible to do this task more easily and declaratively\n",
        "\n",
        "* <font color=\"red\">Warning:</font> I could not (and do not want to) decipher this [super lawyerish spec document about it](https://www.openmp.org/spec-html/5.0/openmpsu109.html#x142-6180002.19.7) to fully understand the behavior of `map` clauses\n",
        "* I am trying to explain it hopefully in a more non-lawyer-friendly and straight-to-the-point way, but part of it is not backed up by the spec document but rather based on actual experiments and my imagination and common sense about what the implementation is doing\n",
        "* when you are not sure, play safe or conduct a similar experiment yourself\n",
        "\n",
        "* <font color=\"blue\">syntax:</font>\n",
        "```\n",
        "#pragma omp target data map(to: ...) map(from: ...) map(tofrom: ...) ...\n",
        "    S\n",
        "```\n",
        "where ... is a variable, array name, or base address + range (e.g., a[0:n])\n",
        "\n",
        "* basically, these clauses say that specified variables, arrays, or address ranges are valid expressions you can get \"expected\" values in the during or after $S$\n",
        "* more specifically, \n",
        "  * those specified in `map(to: ...)` become valid on GPU during $S$\n",
        "  * those specified in `map(from: ...)` become valid on CPU after $S$\n",
        "* to accomplish that, the <font color=\"blue\">_mapping_</font> between CPU address and GPU address are maintained by the runtime system and contents may be moved to or from GPU as necessary\n",
        "  * data specified in `map(to: ...)` may be copied to GPU (CPU -&gt; GPU) before $S$\n",
        "  * data specified in `map(from: ...)` may be copied from GPU (GPU -&gt; CPU) after $S$\n",
        "* `map(tofrom: ...)` has the effect of both; it makes data available to GPU during $S$ and to CPU after $S$\n",
        "\n",
        "* it helps you understand if you think it has two effects\n",
        "  * one is \"transfer data\" that may be accessed from GPU\n",
        "  * the other is \"redirecting pointers\" so that the same expression (e.g., a, a[i], p->x) accesses different locations depending on whether you are on GPU or CPU\n",
        "\n",
        "* you typically use this directive together with `#pragma omp target` and you can in fact specify these clauses in `#pragma omp target`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-067",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-1. local variables and arrays",
        "\n",
        "* local variables and arrays that do not appear in any `map` clause are sent to GPU automatically\n",
        "* so, normally, you don't have to write anything to use (i.e., read) local variables/arrays visible in the scope of `#pragma target` directive\n",
        "note that a local arrays (`a`) and a structure (`p`) seems available without any declaration\n",
        "* the following program demonstrates that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-068",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_local.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "struct point { float x; float y; };\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  point p = { t + 3, t + 4 };\n",
        "  // you do not have to explicitly say anything about t, a, or p.\n",
        "  // they are automatically available on GPU\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"p = { %f, %f }\\n\", p.x, p.y);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-069",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_local.cc -o omp_map_local\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_local.cc -o omp_map_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-070",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-071",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-2. need map(from: $x$) or map(tofrom: $x$) to get the result back",
        "\n",
        "* the following code fails to obtain the result written to variable `t`\n",
        "  * to my surprise, values written to `a` and `p` are available back on CPU\n",
        "  * I didn't try to decipher [the lawyerish spec document](https://www.openmp.org/spec-html/5.0/openmpsu109.html#x142-6180002.19.7) to understand this behavior\n",
        "  * for now, I think it's a safe bet to always specify variables through which you want to obtain results from GPU when you are not sure\n",
        "\n",
        "* you need to specify `map` clause for `t`, either with `map(from: t)` when you don't have to send the value set by CPU to GPU, or with `map(tofrom: t)` when you have to\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-072",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_from.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "struct point {\n",
        "  float x;\n",
        "  float y;\n",
        "};\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  point p = { t + 3, t + 4 };\n",
        "#pragma omp target \n",
        "  {\n",
        "    t *= 2.0;\n",
        "    for (int i = 0; i < 3; i++) a[i] *= 2.0;\n",
        "    p.x *= 2.0; p.y *= 2.0;\n",
        "  }\n",
        "  printf(\"t = %f\\n\", t);\n",
        "  printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  printf(\"p = { %f, %f }\\n\", p.x, p.y);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-073",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_from.cc -o omp_map_from\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_from.cc -o omp_map_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-074",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-075",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 5 :  Use map(from: ..) or map(tofrom: ..) to get the result back</font>",
        "\n",
        "* add an appropriate `map` clause above so the CPU can get all the results back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-010",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-076",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-3. global variables and arrays",
        "\n",
        "* global variables and arrays are similar to local variables and arrays in that they are sent to GPU automatically when they do not appear in any `map` clause \n",
        "* again, the opposite is not true"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-077",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_global.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "struct point {\n",
        "  float x;\n",
        "  float y;\n",
        "};\n",
        "\n",
        "float t;\n",
        "float a[3];\n",
        "point p;\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  for (int i = 0; i < 3; i++) { a[i] = t + i; }\n",
        "  p.x = t + 3; p.y = t + 4;\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"p = { %f, %f }\\n\", p.x, p.y);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-078",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_global.cc -o omp_map_global\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_global.cc -o omp_map_global"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-079",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_global"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-080",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-4. what happens on pointers?",
        "\n",
        "* interestingly, a local pointer pointing to another local variable or an array mapped by a map clause (or a lack thereof) gets automatically \"redirected\" so that it points to the GPU version\n",
        "ints to (`a`) are automatically mapped on GPU\n",
        "* in the following program, data access through a pointer `pa` are valid without any map clause, as the data it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-081",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  float * pa = a;\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\" a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-082",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_ptr.cc -o omp_map_ptr\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr.cc -o omp_map_ptr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-083",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_ptr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-084",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* it's interesting to see the addresses of these data\n",
        "* the addresses of array `a` are naturally different between CPU and GPU\n",
        "* remarkably, the addresses held in a pointer variable `pa` are _adjusted_ so it now points to the GPU version of `a`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-085",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr_with_addr.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  float * pa = a;\n",
        "  printf(\"[host]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"[dev ]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-086",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_ptr_with_addr.cc -o omp_map_ptr_with_addr\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_with_addr.cc -o omp_map_ptr_with_addr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-087",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_ptr_with_addr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-088",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* this adjustment happens because `a` is mapped on the GPU as well, due to expressions involving `a`, such as `a[0]`, `a[1]`, etc. appear in the target statement\n",
        "d you get an error\n",
        "* if you remove the first statement to leave only the expressions involving `pa`, the adjustment does not occur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-089",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr_err.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  float * pa = a;\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-090",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_ptr_err.cc -o omp_map_ptr_err\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_err.cc -o omp_map_ptr_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-091",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_ptr_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-092",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-5. a pointer buried in another data",
        "\n",
        "* another situation you need to explicitly handle data mapping is when a pointer is buried in another data structure (e.g., a struct containing a pointer)\n",
        "* such a pointer is not automatically _adjusted_ even if it happens to point to a local variable or an array that will be mapped automatically or by an explicit `map` clause\n",
        "\n",
        "* here is an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-093",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr_in_data.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "struct cell {\n",
        "  float x;\n",
        "  float * a;\n",
        "};\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  cell c = { t + 3, a };\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"  t = %f\\n\", t);\n",
        "    printf(\"  a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"c.x = %f\\n\", c.x);\n",
        "    printf(\"c.a = %p\\n\", c.a);\n",
        "    printf(\"c.a = { %f, %f, %f }\\n\", c.a[0], c.a[1], c.a[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-094",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_ptr_in_data.cc -o omp_map_ptr_in_data\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_in_data.cc -o omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-095",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-096",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 6 :  make pointer in another data structure valid</font>",
        "\n",
        "* specify a map clause to indicate that you want to read `c.a[0:3]` in GPU\n",
        "* <font color=\"red\">if you do that, however, a surprising side effect happens (another thing I couldn't get yet witness by yourself and fix it\n",
        "from the spec)</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-097",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr_in_data.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "struct cell {\n",
        "  float x;\n",
        "  float * a;\n",
        "};\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  cell c = { t + 3, a };\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"  t = %f\\n\", t);\n",
        "    printf(\"  a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"c.x = %f\\n\", c.x);\n",
        "    printf(\"c.a = %p\\n\", c.a);\n",
        "    printf(\"c.a = { %f, %f, %f }\\n\", c.a[0], c.a[1], c.a[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-098",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_ptr_in_data.cc -o omp_map_ptr_in_data\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_in_data.cc -o omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-011",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-099",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-6. pointer to heap-allocated data",
        "\n",
        "* it's not that everything is handled so nicely, of course\n",
        "* the most basic situation you need to handle yourself is a pointer to heap-allocated data (by `malloc` or `new`, or anything other than local/global variables/arrays visible and used in `target`, as a matter of fact)\n",
        "* in these cases you need to explicitly specify a pointer and a range you want to make valid on GPU, by a range expression like <font color=\"blue\">_p_[_start_:_end_]</font> or <font color=\"blue\">_p_[_start_:_end_:_stride_]</font>\n",
        "\n",
        "* here is an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-100",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_heap.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float * a = new float[3];     // heap-allocated data\n",
        "  for (int i = 0; i < 3; i++) { a[i] = t + i; }\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-101",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_heap.cc -o omp_map_heap\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_heap.cc -o omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-102",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-103",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 7 :  Use `map` clause (with a range expression) to make pointer to heap valid</font>",
        "\n",
        "* add an appropriate `map` clause so the GPU can get data in array `a` from CPU\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-104",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_heap.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float * a = new float[3];     // heap-allocated data\n",
        "  for (int i = 0; i < 3; i++) { a[i] = t + i; }\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-105",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu omp_map_heap.cc -o omp_map_heap\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_map_heap.cc -o omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-012",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-106",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-7. GOOD NEWS: `nvc(++) -gpu=mem:managed` makes heap-allocated data automatically shared",
        "\n",
        "* If you give `-gpu=mem:managed` option to NVIDIA HPC SDK compiler (`nvc` or `nvc++`), heap-allocated data --- data allocated by `malloc` or `new` --- get automatically shared\n",
        "* This makes working on pointer-based data structures particularly easy\n",
        "\n",
        "* Notes:\n",
        "  * This is presumably implemented by replacing calls to `malloc` by `cudaMallocManaged`\n",
        "  * Data allocated by `mmap` is NOT shared on this platform\n",
        "  * More recent OS supporting the hierarchical memory management (HMM) share mmap-allocated data, too\n",
        "    * [Details](https://developer.nvidia.com/blog/simplifying-gpu-application-development-with-heterogeneous-memory-management/)\n",
        "  * More recent GPUs supporting hardware unified memory share local variables and global variables data, too\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-107",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_nomap_heap.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float * a = new float[3];     // heap-allocated data\n",
        "  for (int i = 0; i < 3; i++) { a[i] = t + i; }\n",
        "#pragma omp target\n",
        "  {\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-108",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -mp=gpu -gpu=mem:managed omp_nomap_heap.cc -o omp_nomap_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-109",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_nomap_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-110",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 11. Summary : when is `map` clause necessary?",
        "\n",
        " |allocated as/by       |syntax                        |CPU -> GPU         |GPU -> CPU         | Remarks |\n",
        " |----------------------|------------------------------|-------------------|-------------------|---------|\n",
        " |local/global variable |`int v;`                      |                   |`map(from:v)`      |         |\n",
        " |local/global array    |`int a[N];`                   |                   |`map(from:a[p:q])` |         |\n",
        " |malloc/new            |`int * h = (int *)malloc(..);`|`map(to:h[p:q])`   |`map(to:h[p:q])`   | \\*      |\n",
        " |                      |`int * h = new int[N];`       |`map(to:h[p:q])`   |`map(to:h[p:q])`   | \\*      |\n",
        " |mmap                  |`int * h = (int *)mmap(..);`  |`map(to:h[p:q])`   |`map(to:h[p:q])`   |         |\n",
        "\n",
        "* \\* unnecessary when `nvc++ -gpu=mem:managed` option\n",
        "* Therefore, if you\n",
        "  * restrict GPU-to-CPU communication to data allocated by malloc or new (i.e., not through local or global variables), and \n",
        "  * do not use mmap,\n",
        "  \n",
        "then map clauses are unnecessary by using the `nvc++ -gpu=mem:managed` option.\n",
        "* That is, the data will largely be transparently shared between the GPU and CPU\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-111",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 12. Visualizing execution",
        "\n",
        "* Let's perform the same experiment we did for multicore before, this time on GPU\n",
        "* The program below executes the function `iter_fun`\n",
        "```\n",
        "#pragma omp target teams distribute parallel for num_teams(n_teams) num_threads(n_threads_per_team)\n",
        "  for (long i = 0; i < L; i++) {\n",
        "    iter_fun(a, b, i, M, N, R, T);\n",
        "  }\n",
        "```\n",
        "\n",
        "* `iter_fun(a, b, i, M, N, R, T)` repeats x = a x + b many (M * N) times and record time every N iterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-013",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile omp_gpu_sched_rec.cc\n",
        "#include <assert.h>\n",
        "#include <err.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <omp.h>\n",
        "#include <nv/target>\n",
        "\n",
        "long cur_time_ns() {\n",
        "  struct timespec ts[1];\n",
        "  if (clock_gettime(CLOCK_REALTIME, ts) == -1) err(1, \"clock_gettime\");\n",
        "  return ts->tv_sec * 1000000000L + ts->tv_nsec;\n",
        "}\n",
        "\n",
        "#if __NVCOMPILER\n",
        "/* get SM id (for NVIDIA compiler).\n",
        "   return -1 if called on CPU */\n",
        "__host__ __device__ static unsigned int get_smid(void) {\n",
        "  if target(nv::target::is_device) {\n",
        "    unsigned int sm;\n",
        "    asm(\"mov.u32 %0, %%smid;\" : \"=r\"(sm));\n",
        "    return sm;\n",
        "  } else {\n",
        "    return (unsigned int)(-1);\n",
        "  }\n",
        "}\n",
        "#endif\n",
        "\n",
        "#if __clang__\n",
        "/* get SM id (for Clang LLVM compiler).\n",
        "   return -1 if called on CPU */\n",
        "__attribute__((unused))\n",
        "static unsigned int get_smid(void) {\n",
        "#if __CUDA_ARCH__\n",
        "  unsigned int sm;\n",
        "  asm(\"mov.u32 %0, %%smid;\" : \"=r\"(sm));\n",
        "  return sm;\n",
        "#else\n",
        "  return (unsigned int)(-1);\n",
        "#endif\n",
        "}\n",
        "\n",
        "/* get GPU clock (for Clang LLVM compiler).\n",
        "   return -1 if called on CPU */\n",
        "__attribute__((unused))\n",
        "static long long int clock64(void) {\n",
        "#if __CUDA_ARCH__\n",
        "  long long int clock;\n",
        "  asm volatile(\"mov.s64 %0, %%clock64;\" : \"=r\" (clock));\n",
        "  return clock;\n",
        "#else\n",
        "  return (unsigned int)(-1);\n",
        "#endif\n",
        "}\n",
        "#endif\n",
        "\n",
        "__attribute__((unused))\n",
        "static long long int get_gpu_clock(void) {\n",
        "  long long int t = 0;\n",
        "#pragma omp target map(from: t)\n",
        "  t = clock64();\n",
        "  return t;\n",
        "}\n",
        "\n",
        "typedef struct {\n",
        "  double x;\n",
        "  int team[2];\n",
        "  int thread[2];\n",
        "  int sm[2];\n",
        "} record_t;\n",
        "\n",
        "/* the function for an iteration\n",
        "   perform\n",
        "   x = a x + b\n",
        "   (M * N) times and record current time\n",
        "   every N iterations to T.\n",
        "   record thread and cpu to R.\n",
        " */\n",
        "void iter_fun(double a, double b, long i, long M, long N,\n",
        "              record_t * R, long * T) {\n",
        "  // initial value (not important)\n",
        "  double x = i;\n",
        "  // record in T[i * M] ... T[(i+1) * M - 1]\n",
        "  T = &T[i * M];\n",
        "  // record starting thread/cpu\n",
        "  R[i].team[0] = omp_get_team_num();\n",
        "  R[i].thread[0] = omp_get_thread_num();\n",
        "  R[i].sm[0] = get_smid();\n",
        "  // repeat a x + b many times.\n",
        "  // record time every N iterations\n",
        "  for (long j = 0; j < M; j++) {\n",
        "    T[j] = clock64();\n",
        "    for (long k = 0; k < N; k++) {\n",
        "      x = a * x + b;\n",
        "    }\n",
        "  }\n",
        "  // record ending SM (must be = thread0)\n",
        "  R[i].team[1] = omp_get_team_num();\n",
        "  R[i].thread[1] = omp_get_thread_num();\n",
        "  R[i].sm[1] = get_smid();\n",
        "  // record result, just so that the computation is not\n",
        "  // eliminated by the compiler\n",
        "  R[i].x = x;\n",
        "}\n",
        "\n",
        "void dump(record_t * R, long * T, long L, long M) {\n",
        "  long t0 = LONG_MAX;\n",
        "  long k = 0;\n",
        "  assert(L * M > 0);\n",
        "  // find min clock\n",
        "  for (long i = 0; i < L; i++) {\n",
        "    for (long j = 0; j < M; j++) {\n",
        "      t0 = (T[k] < t0 ? T[k] : t0);\n",
        "      k++;\n",
        "    }\n",
        "  }\n",
        "  assert(t0 < LONG_MAX);\n",
        "  k = 0;\n",
        "  for (long i = 0; i < L; i++) {\n",
        "    printf(\"i=%ld x=%f team0=%d thread0=%d sm0=%d team1=%d thread1=%d sm1=%d\",\n",
        "           i, R[i].x,\n",
        "           R[i].team[0], R[i].thread[0], R[i].sm[0],\n",
        "           R[i].team[1], R[i].thread[1], R[i].sm[1]);\n",
        "    for (long j = 0; j < M; j++) {\n",
        "      printf(\" %ld\", T[k] - t0);\n",
        "      k++;\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "}\n",
        "\n",
        "int getenv_int(const char * v) {\n",
        "  char * s = getenv(v);\n",
        "  if (!s) {\n",
        "    fprintf(stderr, \"specify environment variable %s\\n\", v);\n",
        "    exit(1);\n",
        "  }\n",
        "  return atoi(s);\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int idx = 1;\n",
        "  long L   = (idx < argc ? atol(argv[idx]) : 100);  idx++;\n",
        "  long M   = (idx < argc ? atol(argv[idx]) : 100);  idx++;\n",
        "  long N   = (idx < argc ? atol(argv[idx]) : 100);  idx++;\n",
        "  double a = (idx < argc ? atof(argv[idx]) : 0.99); idx++;\n",
        "  double b = (idx < argc ? atof(argv[idx]) : 1.00); idx++;\n",
        "  int n_teams = getenv_int(\"OMP_NUM_TEAMS\");\n",
        "  int n_threads_per_team = getenv_int(\"OMP_NUM_THREADS\");\n",
        "  record_t * R = (record_t *)calloc(L, sizeof(record_t));\n",
        "  long * T = (long *)calloc(L * M, sizeof(long));\n",
        "  long t0 = get_gpu_clock();\n",
        "#pragma omp target teams distribute parallel for num_teams(n_teams) num_threads(n_threads_per_team) map(tofrom: R[:L]) map(tofrom: T[:L*M])\n",
        "  for (long i = 0; i < L; i++) {\n",
        "    iter_fun(a, b, i, M, N, R, T);\n",
        "  }\n",
        "  long t1 = get_gpu_clock();\n",
        "  printf(\"%ld GPU clocks\\n\", t1 - t0);\n",
        "  dump(R, T, L, M);\n",
        "  return 0;\n",
        "}\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-014",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvc++ -mp=gpu -cuda omp_gpu_sched_rec.cc -o omp_gpu_sched_rec\n",
        "# clang++ -Wall -fopenmp -fopenmp-targets=nvptx64 omp_gpu_sched_rec.cc -o omp_gpu_sched_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-015",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_gpu_sched_rec > a.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-112",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Execute the following cell to visialize it\n",
        "* In the graph,\n",
        "  * horizontal axis is the time from the start in the number of clock cycles on GPU\n",
        "  * vertical axis is the iteration number (i)\n",
        "  * the color represents the thread that executed the iteration\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-016",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "import sched_vis\n",
        "omp_gpu_sched_vis.sched_plt([\"a.dat\"])\n",
        "# omp_gpu_sched_vis.sched_plt([\"a.dat\"], start_t=1.5e7, end_t=2.0e7, show_every=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-113",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 8 :  Understanding scheduling by visualization</font>",
        "\n",
        "* Set the number of teams to 1 and increase the number of threads (per team) from 32 to larger numbers, to find how many iterations can execute almost simultaneously in a single team (i.e., SM)\n",
        "  * use `show_every` parameter to reduce the number of iterations visualized \n",
        "* Then you fix the number of threads per team and increase the number of teams, again to find how many iterations can execute almost simultaneously in the device\n",
        "* Find the equivalent number on CPU and compare them\n",
        "  * You will confirm the number for GPU is much larger than that for CPU, with no surprise\n",
        "  * Make no mistake; CPU has other axes of parallelism (SIMD and superscalar) that cannot be tapped just by using multicores (omp parallel), which we will see later in this course (do not interpret the ratio between the two as the ratio of the peak performance between the two)\n",
        "  * Still, it's safe to say GPU \"simplifies\" high-performance programming, in the sense that the required effort to tap all available hardware-level parallelism is much lower if the program has ample loop-level parallelism (the number of independently executable iterations)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-114",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 9 :  Putting them together: calculating an integral</font>",
        "\n",
        "Write an OpenMP program that calculates\n",
        "\n",
        "$$ \\int \\int_D \\sqrt{1 - x^2 - y^2}\\,dx\\,dy $$\n",
        "\n",
        "where\n",
        "\n",
        "$$ D = \\{\\;(x, y)\\;|\\;0\\leq x \\leq 1, 0\\leq y \\leq 1, x^2 + y^2 \\leq 1 \\}$$\n",
        "\n",
        "<font color=red>on GPU.</font>\n",
        "\n",
        "* Note: an alternative way to put it is to calculate\n",
        "\n",
        "$$ \\int_0^1 \\int_0^1 f(x)\\,dx\\,dy $$\n",
        "\n",
        "where\n",
        "\n",
        "$$ f(x) = \\left\\{\\begin{array}{ll}\\sqrt{1 - x^2 - y^2} & (x^2 + y^2 \\leq 1) \\\\ 0 & (\\mbox{otherwise}) \\end{array}\\right. $$\n",
        "\n",
        "* Use a nested loop to calculate the double integral\n",
        "* Use `target`, `teams`, `distribute`, `parallel`, and `for` to execute it on GPU\n",
        "* The result should be close to $\\pi/6 = 0.52359..$ (1/8 of the volume of the unit ball)\n",
        "* Play with the number of infinitesimal intervals for integration and the number of threads so that you can observe a speedup\n",
        "\n",
        "* Take the number of thread blocks (passed to `num_teams(..)`) and the number of threads per block (passed to `num_threads(x)`) in the command line\n",
        "\n",
        "* Compare the execution speed of OpenMP (CPU), CUDA (GPU), and OpenMP (GPU) in various settings\n",
        "  * a single CPU thread vs single CUDA thread\n",
        "  * a single CPU thread vs multiple CUDA threads in a single thread block \n",
        "  * multiple CPU threads vs multiple CUDA threads in multiple thread blocks\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-017",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile omp_gpu_integral.cc\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-115",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -O4 -mp=gpu omp_gpu_integral.cc -o omp_gpu_integral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-116",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_gpu_integral"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "SoS",
      "language": "sos",
      "name": "sos"
    },
    "language_info": {
      "codemirror_mode": "sos",
      "file_extension": ".sos",
      "mimetype": "text/x-sos",
      "name": "sos",
      "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
      "pygments_lexer": "sos"
    },
    "sos": {
      "kernels": [
        [
          "Bash",
          "bash",
          "bash",
          "",
          "shell"
        ],
        [
          "C",
          "c_kernel",
          "c",
          "",
          ""
        ],
        [
          "Go",
          "gophernotes",
          "go",
          "",
          ""
        ],
        [
          "Julia 1.10.2",
          "julia-1.10",
          "julia",
          "",
          ""
        ],
        [
          "OCaml default",
          "ocaml-jupyter",
          "OCaml",
          "",
          "text/x-ocaml"
        ],
        [
          "Python 3 (ipykernel)",
          "python3",
          "python3",
          "",
          {
            "name": "ipython",
            "version": 3
          }
        ],
        [
          "Rust",
          "rust",
          "rust",
          "",
          ""
        ]
      ],
      "panel": {
        "displayed": true,
        "height": 0
      },
      "version": "0.23.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}