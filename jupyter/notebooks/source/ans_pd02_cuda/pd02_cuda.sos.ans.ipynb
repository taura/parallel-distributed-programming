{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-001",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "#  CUDA Programming Tutorial and Hands-on",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-002",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "Enter your name and student ID.\n",
        "\n",
        " * Name:\n",
        " * Student ID:\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-003",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 1. CUDA",
        "\n",
        "* [CUDA](https://docs.nvidia.com/cuda/index.html) is an extension to C++ specific to NVIDIA GPUs\n",
        "* It is the most basic, native programming model for NVIDIA GPUs\n",
        "\n",
        "# 2. Compilers",
        "\n",
        "* We use [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) (`nvcc`) for CUDA compilers\n",
        "* [LLVM ver. 18.1.8](https://llvm.org/) (`clang` and `clang++`) and NVIDA's C/C++ compilers (`nvc` and `nvc++`) we used for OpenMP also support CUDA, but they fail to compile some of our code, so we stick to more traditional `nvcc`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-004",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-1. Set up NVIDIA CUDA and HPC SDK",
        "\n",
        "Execute this before you use NVIDIA HPC SDK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-005",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/24.9/compilers/bin:$PATH\n",
        "export PATH=/usr/local/cuda/bin:$PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-006",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Check if it works\n",
        "  * make sure the full path of nvcc is shown as `/usr/local/...`, not `/opt/nvidia/...`\n",
        "* We do not recommend nvc/nvc++ for this exercise, but you might give them a try if you like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-007",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which nvcc\n",
        "which nvc\n",
        "which nvc++\n",
        "nvcc --version\n",
        "nvc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-008",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-2. LLVM",
        "\n",
        "* We do not recommend it for this exercise, but you might give them a try if you like\n",
        "* Execute this before you use LLVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-009",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/home/share/llvm/bin:$PATH\n",
        "export LD_LIBRARY_PATH=/home/share/llvm/lib:/home/share/llvm/lib/x86_64-unknown-linux-gnu:$LD_LIBRARY_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-010",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Check if it works (check if full paths of clang/clang++ are shown)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-011",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which clang\n",
        "which clang++\n",
        "clang --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-012",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 3. Check host and GPU",
        "\n",
        "* First check if you are using the right host, tauleg000, <font color=\"red\">not taulec</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-013",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "hostname\n",
        "hostname | grep tauleg || echo \"Oh, you are not on the right host, access https://tauleg.zapto.org/ instead\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-014",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Check if GPU is alive by nvidia-smi\n",
        "* Do `nvidia-smi --help` or see manual (`man nvidia-smi` on terminal) for more info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-015",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-016",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 4. Compiling and running CUDA programs",
        "\n",
        "## 4-1. With nvcc (NVIDIA HPC SDK CUDA compiler)",
        "\n",
        "* Give a source file `.cu` extension or give `--x cu` option to indicate it is a CUDA source file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-001",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int nthreads = gridDim.x * blockDim.x;\n",
        "  if (i < n) {\n",
        "    printf(\"hello I am CUDA thread %d out of %d\\n\", i, nthreads);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 100);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  // launch a kernel\n",
        "  cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(n);\n",
        "  // wait for them to complete\n",
        "  cudaDeviceSynchronize();\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-002",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello cuda_hello.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-003",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* You should see 100 lines of \"hello I am CUDA thread ??? out of 128\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-018",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Alternatively, you can have a source file with an ordinary C++ extension `.cc` (or `.cpp`) and give `-x cu`.\n",
        "* It is useful when you want to have a single source file for OpenMP and CUDA programs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-019",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "ln -sf cuda_hello.cu cuda_hello.cc\n",
        "nvcc -o cuda_hello -x cu cuda_hello.cc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-020",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_hello"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-021",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 4-2. With nvc++ (NVIDIA HPC SDK C++ compiler)",
        "\n",
        "* Just to demonstrate `nvc++` supports CUDA, too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-004",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvc++ -Wall -o cuda_hello cuda_hello.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-022",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -Wall -o cuda_hello -x cu cuda_hello.cc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-023",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 4-3. With clang++ (LLVM)",
        "\n",
        "* Just to demonstrate `clang++` supports CUDA, too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-005",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "clang++ -Wall -o cuda_hello cuda_hello.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-024",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "ln -sf cuda_hello.cu cuda_hello.cc\n",
        "clang++ -Wall -o cuda_hello -x cu cuda_hello.cc -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-025",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 5. CUDA kernel",
        "\n",
        "* The most basic concept of CUDA programming is a _CUDA kernel_\n",
        "* Syntactically, a CUDA kernel is a `void` function with `__global__` keyword attached to it\n",
        "```\n",
        "__global__ void cuda_thread_fun(int n) { ... }\n",
        "```\n",
        "* A CUDA kernel describes what a _single_ CUDA thread does\n",
        "* You launch a number of CUDA threads all executing the same kernel by \n",
        "```\n",
        "kernel_func<<<num_of_blocks,num_of_threads_per_block>>>(...);\n",
        "```\n",
        "* We have already seen this in the above code\n",
        "* See [2. Programming model](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model) section for reference\n",
        "\n",
        "## 5-1. <font color=\"red\">You'd better always check errors</font>",
        "\n",
        "* It's not only CUDA programming in which you are strongly advised to check errors after each operation that could potentially go wrong\n",
        "* Just like many C programming APIs (unlike Python scripting, for example), calling CUDA APIs and launching CUDA kernels silently return if something went wrong\n",
        "* You could save a huge amount of time by checking errors \n",
        "  * every time you launch a CUDA kernel and\n",
        "  * every time you call a CUDA API\n",
        "\n",
        "* Here is the same piece of code with checking errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-006",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello_chk.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        "  you'd better spend time on making sure you always check errors ...\n",
        "*/\n",
        "\n",
        "void check_api_error_(cudaError_t e,\n",
        "                      const char * msg, const char * file, int line) {\n",
        "  if (e) {\n",
        "    fprintf(stderr, \"%s:%d:error: %s %s\\n\",\n",
        "            file, line, msg, cudaGetErrorString(e));\n",
        "    exit(1);\n",
        "  }\n",
        "}\n",
        "\n",
        "#define check_api_error(e) check_api_error_(e, #e, __FILE__, __LINE__)\n",
        "\n",
        "void check_launch_error_(const char * msg, const char * file, int line) {\n",
        "  cudaError_t e = cudaGetLastError();\n",
        "  if (e) {\n",
        "    fprintf(stderr, \"%s:%d:error: %s %s\\n\",\n",
        "            file, line, msg, cudaGetErrorString(e));\n",
        "    exit(1);\n",
        "  }\n",
        "}\n",
        "\n",
        "#define check_launch_error(exp) do { exp; check_launch_error_(#exp, __FILE__, __LINE__); } while (0)\n",
        "\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int nthreads = gridDim.x * blockDim.x;\n",
        "  if (i < n) {\n",
        "    printf(\"hello I am CUDA thread %d out of %d\\n\", i, nthreads);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 100);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-007",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello_chk cuda_hello_chk.cu\n",
        "# nvc++ -Wall -o cuda_hello_chk cuda_hello_chk.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_hello_chk cuda_hello_chk.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-008",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_chk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-026",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* I factored out the error-checking code into a header file `\"cuda_util.h\"` and included it in the directory (check it from the left menu)\n",
        "* The following code is a more concise version using the header file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-009",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello_hdr_chk.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int nthreads = gridDim.x * blockDim.x;\n",
        "  if (i < n) {\n",
        "    printf(\"hello I am CUDA thread %d out of %d\\n\", i, nthreads);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 100);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-010",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello_hdr_chk cuda_hello_hdr_chk.cu\n",
        "# nvc++ -Wall -o cuda_hello_hdr_chk cuda_hello_hdr_chk.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_hello_hdr_chk cuda_hello_hdr_chk.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-011",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_hdr_chk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-027",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 6. The number of CUDA threads launched",
        "\n",
        "* You specify the number of threads launched by the two parameters in <<<...,...>>>, like\n",
        "```\n",
        "kernel_func<<<num_of_blocks,num_of_threads_per_block>>>(...);\n",
        "```\n",
        "\n",
        "* It will create (num_of_blocks * num_of_threads_per_block) threads in total.\n",
        "* More precisely, it creates num_of_blocks _thread blocks_, each of which has num_of_threads_per_block threads.\n",
        "* It is natural to wonder why you need to specify two parameters instead of just one parameter (the total number of threads) and how to choose num_of_threads_per_block.\n",
        "* For now, just know that a thread block is the unit of scheduling\n",
        "  * A GPU device fetches a single block at a time and dispatches it to a particular streaming multiprocessor (SM)\n",
        "  * Remember that a single SM is like a CPU core; a single GPU device has a number of SMs just like a single CPU has a number of cores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-028",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 1 :  Change the number of threads per block</font>",
        "\n",
        "Change the arguments of the following command line in various ways and see what happens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-012",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_hdr_chk 10 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-029",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Answer for trivial work omitted</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-030",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 7. Thread ID",
        "\n",
        "## 7-1. One-dimensional ID",
        "\n",
        "* Just like OpenMP, CUDA provides a means for a thread to know its ID as well as the total number of threads launched together\n",
        "* They are obtained from builtin variables\n",
        "* Let's say you invoked a kernel with\n",
        "```\n",
        "f<<<12,34>>>(...);\n",
        "```\n",
        "you create 12 thread blocks having 34 threads each (408 threads in total).\n",
        " * `gridDim.x` gives the number of thread blocks ($= 12$)\n",
        " * `blockDim.x` gives the number of threads in a thread block ($= 34$)\n",
        "\n",
        "* note: \"grid\" is the CUDA terminology to mean all the launched thread blocks (a CUDA thread $\\in$ thread block $\\in$ the entire grid)\n",
        "\n",
        " * `blockIdx.x` gives the block ID within the grid ($\\in [0,12)$) \n",
        " * `threadIdx.x` gives the thread ID within a thread block ($\\in [0,34)$)\n",
        "* If you want to get a single thread ID between 0 to 407 and the total number of threads, you get them by\n",
        "```\n",
        "int idx      = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "int nthreads = gridDim.x * blockDim.x;\n",
        "```\n",
        "* You have seen them in the above example.\n",
        "\n",
        "* See [2.1 Kernels](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#kernels) for reference\n",
        "\n",
        "## 7-2. Two- or three-dimensional ID",
        "\n",
        "* Each of the above four variables can actually have up to three elements, allowing you to view blocks and threads within a block arranged in an one-, two- or three-dimensional space.  \n",
        "* You specify them accordingly when you call a kernel, for which you use a variable of type `dim3` instead of an integer, to specify up to three numbers\n",
        "\n",
        "* See [2.2 Thread Hierarchy](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy) for reference\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-013",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello_2d.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int x          = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int y          = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "  int nthreads_x = gridDim.x * blockDim.x;\n",
        "  int nthreads_y = gridDim.y * blockDim.y;\n",
        "  int g          = x + nthreads_y * y;\n",
        "  if (g < n) {\n",
        "    printf(\"hello I am CUDA thread (%d,%d) of (%d,%d)\\n\",\n",
        "           x, y, nthreads_x, nthreads_y);\n",
        "  }\n",
        "}\n",
        "\n",
        "int isqrt(int n) {\n",
        "  int i;\n",
        "  for (i = 0; i * i < n; i++) ;\n",
        "  return i;\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n                 = (argc > 1 ? atoi(argv[1]) : 40);\n",
        "  int nx                = isqrt(n);\n",
        "  int ny                = (n + nx - 1) / nx;\n",
        "  int thread_block_sz_x = (argc > 2 ? atoi(argv[2]) : 2);\n",
        "  int thread_block_sz_y = (argc > 3 ? atoi(argv[3]) : 3);\n",
        "  int n_thread_blocks_x = (nx + thread_block_sz_x - 1) / thread_block_sz_x;\n",
        "  int n_thread_blocks_y = (ny + thread_block_sz_y - 1) / thread_block_sz_y;\n",
        "  printf(\"(%d * %d) threads/block * (%d * %d) blocks\\n\",\n",
        "         thread_block_sz_x, thread_block_sz_y,\n",
        "         n_thread_blocks_x, n_thread_blocks_y);\n",
        "\n",
        "  dim3 nb(n_thread_blocks_x, n_thread_blocks_y);\n",
        "  dim3 tpb(thread_block_sz_x, thread_block_sz_y);\n",
        "  check_launch_error((cuda_thread_fun<<<nb,tpb>>>(n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-014",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello_2d cuda_hello_2d.cu\n",
        "# nvc++ -Wall -o cuda_hello_2d cuda_hello_2d.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_hello_2d cuda_hello_2d.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-015",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-031",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 2 :  Specify 2D thread blocks and grids</font>",
        "\n",
        "* Change the arguments of the following command line in various ways and see what happens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-016",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_2d 40 2 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-032",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Answer for trivial work omitted</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-033",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 8. Passing data between host (CPU) and device (GPU)",
        "\n",
        "* GPU is a device separate from a host CPU\n",
        "* As such, CPU and GPU do not share memory; you need to explicitly pass data by calling APIs (this is changing but practically remains true for a while)\n",
        "* One simplest way to pass data from a host to device is arguments to a kernel function, but\n",
        "  * it cannot be used for device -&gt; host (recall that kernel functions are always void)\n",
        "  * it is limited to values passed by \"call-by-value\"; you cannot pass pointers along with values pointed to by them\n",
        "* For anything other than passing arguments by call-by-values, you should use `cudaMalloc` and `cudaMemcpy`\n",
        "\n",
        "* See [3.2.2. Device Memory](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory) for reference\n",
        "\n",
        "## 8-1. cudaMalloc",
        "\n",
        "```\n",
        "void * p;\n",
        "check_api_error(cudaMalloc(&p, size));\n",
        "```\n",
        "\n",
        "* allocates `size` bytes of memory on device and\n",
        "* returns an address valid on the device (not valid on the host) to variable `p`\n",
        "\n",
        "* remember that this function should be called on host; no functions are provided in CUDA API for CUDA threads to dynamically allocate memory along the way\n",
        "\n",
        "## 8-2. cudaMemcpy",
        "\n",
        "* host -&gt; device\n",
        "```\n",
        "check_api_error(cudaMemcpy(p_dev, p_host, size, cudaMemcpyHostToDevice));\n",
        "```\n",
        "\n",
        "* device -&gt; host\n",
        "```\n",
        "check_api_error(cudaMemcpy(p_host, p_dev, size, cudaMemcpyDeviceToHost));\n",
        "```\n",
        "\n",
        "* the first argument is always the destination\n",
        "* p_dev should be an address on device (i.e., that has been allocated by `cudaMalloc`)\n",
        "\n",
        "## 8-3. cudaFree",
        "\n",
        "```\n",
        "check_api_error(cudaFree(dev_p));\n",
        "```\n",
        "\n",
        "* frees memory allocated by cudaMalloc\n",
        "\n",
        "## 8-4. You cannot access malloc-allocated region on the device",
        "\n",
        "* The following code demonstrates that if the device code accesses a region allocated by malloc (or any other host memory including stacks and global variables), you get a segmentation fault on the device\n",
        "\n",
        "* In practice, you never pass the pointer to malloc-allocated area to a kernel\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-017",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_dev_segfault.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long * p, int n) {\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    p[i] = i * i;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  long * c = (long *)malloc(sizeof(long) * n);\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %ld\\n\", i, c[i]);\n",
        "  }\n",
        "  free(c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-018",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_dev_segfault cuda_dev_segfault.cu\n",
        "# nvc++ -Wall -o cuda_dev_segfault cuda_dev_segfault.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_dev_segfault cuda_dev_segfault.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-019",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_dev_segfault"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-034",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "## 8-5. You cannot access cudaMalloc-allocated region on the host",
        "\n",
        "* The following code demonstrates the oppssite; if the host code accesses a region allocated by `cudaMalloc`, you get a segmentation fault on the host\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-020",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_host_segfault.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long * p, int n) {\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    p[i] = i * i;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(long) * n));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %ld\\n\", i, c_dev[i]);\n",
        "  }\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-021",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_host_segfault cuda_host_segfault.cu\n",
        "# nvc++ -Wall -o cuda_host_segfault cuda_host_segfault.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_host_segfault cuda_host_segfault.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-022",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_host_segfault"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-035",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "* So, to get a result computed on the device back to the host, call `cudaMemcpy`\n",
        "\n",
        "# <font color=\"green\"> Problem 3 :  Getting the result back from the device</font>",
        "\n",
        "* Add an appropriate call to `cudaMemcpy` to the following code, so it correctly prints the values computed on the device (i.e., c[i] = i)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-023",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_dev_to_host.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long * p, int n) {\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    p[i] = i * i;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  long * c = (long *)malloc(sizeof(long) * n);\n",
        "  long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(long) * n));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %ld\\n\", i, c[i]);\n",
        "  }\n",
        "  free(c);\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-024",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_dev_to_host cuda_dev_to_host.cu\n",
        "# nvc++ -Wall -o cuda_dev_to_host cuda_dev_to_host.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_dev_to_host cuda_dev_to_host.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-025",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_dev_to_host"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-036",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_dev_to_host_ans.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long * p, int n) {\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    p[i] = i * i;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  long * c = (long *)malloc(sizeof(long) * n);\n",
        "  long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(long) * n));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(c, c_dev, sizeof(long) * n, cudaMemcpyDeviceToHost));\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %ld\\n\", i, c[i]);\n",
        "  }\n",
        "  free(c);\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-037",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc -o cuda_dev_to_host_ans cuda_dev_to_host_ans.cu\n",
        "# nvc++ -Wall -o cuda_dev_to_host_ans cuda_dev_to_host_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_dev_to_host_ans cuda_dev_to_host_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-038",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_dev_to_host_ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-039",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 9. Unified Memory",
        "\n",
        "* Unified Memory is a part of memory accessible both by the host and device\n",
        "* Values written to it by the host are automatically visible to the device and vice versa\n",
        "* Therefore with unified memory you do not have to call `cudaMemcpy` to move data between host and GPU\n",
        "* All you need to master is `cudaMallocManaged`, which you call in place of `cudaMalloc`\n",
        "* You get a pointer that is valid both on CPU and GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-040",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 4 :  Use Unified Memory</font>",
        "\n",
        "* Change the following program so that it uses `cudaMallocManaged` instead of `malloc`\n",
        "* Make other changes as you find them necessary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-026",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_malloc_managed.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long * p, int n) {\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    p[i] = i * i;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  long * c = (long *)malloc(sizeof(long) * n);\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %ld\\n\", i, c[i]);\n",
        "  }\n",
        "  free(c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-027",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_malloc_managed cuda_malloc_managed.cu\n",
        "# nvc++ -Wall -o cuda_malloc_managed cuda_malloc_managed.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_malloc_managed cuda_malloc_managed.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-028",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_malloc_managed 10 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-041",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_malloc_managed_ans.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long * p, int n) {\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    p[i] = i * i;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  long * c;\n",
        "  check_api_error(cudaMallocManaged(&c, sizeof(long) * n));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %ld\\n\", i, c[i]);\n",
        "  }\n",
        "  check_api_error(cudaFree(c));\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-042",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc -o cuda_malloc_managed_ans cuda_malloc_managed_ans.cu\n",
        "# nvc++ -Wall -o cuda_malloc_managed_ans cuda_malloc_managed_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_malloc_managed_ans cuda_malloc_managed_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-043",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_malloc_managed_ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-044",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 10. CUDA device memory model",
        "\n",
        "* memory blocks allocated by `cudaMalloc` are visiable to (shared by) all threads and called _global memory_\n",
        "* they persist on device until you release them by cudaFree (or the process finishes), so they can be used not only to pass values between device and host, but also to pass values between different kernel calls (without moving values back and forth between host and device each time you call a kernel)\n",
        "\n",
        "* See [Memory Hierarchy](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy) for reference\n",
        "\n",
        "# 11. Race condition and atomic operation ",
        "\n",
        "* As threads launched in a single kernel call run concurrently, they are subject to the same race condition as OpenMP threads\n",
        "* That is, if two threads access the same variable (or the same array element) and at least one of them is a write, there is a race and the program almost certainly has a bug\n",
        "\n",
        "* In the following program, each thread increments a variable by one; it nevertheles does not print the number of threads launched and prints unpredictable results each time executed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-029",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_race.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(unsigned long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    *p = *p + 1;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 1000);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  unsigned long long c;\n",
        "  unsigned long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(unsigned long long)));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(&c, c_dev, sizeof(unsigned long long), cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"c = %lu\\n\", c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-030",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_race cuda_race.cu\n",
        "# nvc++ -Wall -o cuda_race cuda_race.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_race cuda_race.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-031",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_race"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-045",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 5 :  Observe race condition</font>",
        "\n",
        "Execute the above program many times and observe the results; try changing parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-032",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_race 1000 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-046",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Answer for trivial work omitted</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-047",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* OpenMP had three basic tools --- critical, atomic and reduction --- to resolve race conditions depending on the situation.\n",
        "* Roughly, CUDA only has an analogue to atomic and does not have critical or reduction.\n",
        "\n",
        "## 11-1. Atomic add",
        "\n",
        "* CUDA has\n",
        "```\n",
        "atomicAdd(T* p, T x);\n",
        "```\n",
        "function for various types of T.  \n",
        "It performs `*p = *p + x` _atomically_, meaning that it is guaranteed that `*p` is not updated between the point `*p` is read and the point `*p` is written.\n",
        "\n",
        "* See [atomicAdd](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomicadd) for reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-048",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 6 :  Use `atomicAdd`</font>",
        "\n",
        "* Change the following program to resolve the race condition using `atomicAdd` and make sure the result always matches the number of threads launched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-033",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_race_atomic_add.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(unsigned long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    *p = *p + 1;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 1000);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  unsigned long long c;\n",
        "  unsigned long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(unsigned long long)));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(&c, c_dev, sizeof(unsigned long long), cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"c = %lu\\n\", c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-049",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* To compile programs using `atomicAdd`, you need to give `--generate-code arch=compute_80,code=sm_80` to `nvcc`\n",
        "* `--generate-code` specifies which GPU architectures/instruction set `nvcc` generates code for, so it might affect generated code in other ways including performance\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-034",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc --generate-code arch=compute_80,code=sm_80 -o cuda_race_atomic_add cuda_race_atomic_add.cu\n",
        "# nvc++ -Wall -gpu=cc80 -o cuda_race_atomic_add cuda_race_atomic_add.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version --cuda-gpu-arch=sm_80 -o cuda_race_atomic_add cuda_race_atomic_add.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-035",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_race_atomic_add 10000 64\n",
        "./cuda_race_atomic_add 100000 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-050",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_race_atomic_add_ans.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(unsigned long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    atomicAdd(p, 1L);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 1000);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  unsigned long long c;\n",
        "  unsigned long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(unsigned long long)));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(&c, c_dev, sizeof(unsigned long long), cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"c = %lu\\n\", c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-051",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc --generate-code arch=compute_80,code=sm_80 -o cuda_race_atomic_add_ans cuda_race_atomic_add_ans.cu\n",
        "# nvc++ -Wall -gpu=cc80 -o cuda_race_atomic_add_ans cuda_race_atomic_add_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version --cuda-gpu-arch=sm_80 -o cuda_race_atomic_add_ans cuda_race_atomic_add_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-052",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_race_atomic_add_ans 10000 64\n",
        "./cuda_race_atomic_add_ans 100000 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-053",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 12. Barrier synchronization of threads",
        "\n",
        "* Recent CUDA has the notion of cooperative groups, with which you can build a barrier synchronization between threads\n",
        "* setup\n",
        "```\n",
        "#include <cooperative_groups.h>\n",
        "namespace cg = cooperative_groups; // save typing\n",
        "```\n",
        "* create data representing a grouup\n",
        "```\n",
        "cg::grid_group g = cg::this_grid(); // all threads\n",
        "```\n",
        "\n",
        "* perform barrier synchronization when necessary (ensure no threads execute `<after>` until all threads finish `<before>`) \n",
        "```\n",
        "  <before>\n",
        "  g.sync();\n",
        "  <after>\n",
        "```\n",
        "\n",
        "* You need to launch such kernels by\n",
        "```\n",
        "void * args[] = { a0, a1, ... };\n",
        "cudaLaunchCooperativeKernel((void *)f, nb, bs, args);\n",
        "```\n",
        "instead of\n",
        "```\n",
        "f<<<nb,bs>>>(a0, a1, ...);\n",
        "```\n",
        "\n",
        "* See [Cooperative Groups](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cooperative-groups) for reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-054",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 7 :  Use barrier synchronization</font>",
        "\n",
        "Change the following program `sum_array()` so that it correctly outputs the sum of the array by implementing reduction on barrier synchronization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-036",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_sum.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "#include <cooperative_groups.h>\n",
        "\n",
        "//using namespace cooperative_groups;\n",
        "// Alternatively use an alias to avoid polluting the namespace with collective algorithms\n",
        "namespace cg = cooperative_groups;\n",
        "\n",
        "__global__ void sum_array(double * c, long n) {\n",
        "  // should return c[0] + c[1] + ... + c[n-1] in c[0]\n",
        "  // you can destroy other elements of the array\n",
        "  cg::grid_group g = cg::this_grid();\n",
        "  long i = g.thread_rank();\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  long n                = (argc > 1 ? atoi(argv[1]) : 10000);\n",
        "  int threads_per_block = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + threads_per_block - 1) / threads_per_block;\n",
        "\n",
        "  double * c = (double *)malloc(sizeof(double) * n);\n",
        "  for (long i = 0; i < n; i++) {\n",
        "    c[i] = 1.0;\n",
        "  }\n",
        "  double * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(double) * n));\n",
        "  check_api_error(cudaMemcpy(c_dev, c, sizeof(double) * n, cudaMemcpyHostToDevice));\n",
        "  void * args[2] = { (void *)&c_dev, (void *)&n };\n",
        "  check_api_error(cudaLaunchCooperativeKernel((void*)sum_array,\n",
        "                                              n_thread_blocks,\n",
        "                                              threads_per_block,\n",
        "                                              args));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(c, c_dev, sizeof(double) * n, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"sum = %f\\n\", c[0]);\n",
        "  assert(c[0] == n);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-037",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_sum cuda_sum.cu\n",
        "# nvc++ -Wall -o cuda_sum cuda_sum.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_sum cuda_sum.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-038",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-055",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_sum_ans.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "#include <cooperative_groups.h>\n",
        "\n",
        "//using namespace cooperative_groups;\n",
        "// Alternatively use an alias to avoid polluting the namespace with collective algorithms\n",
        "namespace cg = cooperative_groups;\n",
        "\n",
        "__global__ void sum_array(double * c, long n) {\n",
        "  // should return c[0] + c[1] + ... + c[n-1] in c[0]\n",
        "  // you can destroy other elements of the array\n",
        "  cg::grid_group g = cg::this_grid();\n",
        "  long i = g.thread_rank();\n",
        "  long h;\n",
        "  for (int m = n; m > 1; m = h) {\n",
        "    h = (m + 1) / 2;\n",
        "    if (i + h < m) {\n",
        "      c[i] += c[i + h];\n",
        "    }\n",
        "    g.sync();\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  long n                = (argc > 1 ? atoi(argv[1]) : 10000);\n",
        "  int threads_per_block = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + threads_per_block - 1) / threads_per_block;\n",
        "\n",
        "  double * c = (double *)malloc(sizeof(double) * n);\n",
        "  for (long i = 0; i < n; i++) {\n",
        "    c[i] = 1.0;\n",
        "  }\n",
        "  double * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(double) * n));\n",
        "  check_api_error(cudaMemcpy(c_dev, c, sizeof(double) * n, cudaMemcpyHostToDevice));\n",
        "  void * args[2] = { (void *)&c_dev, (void *)&n };\n",
        "  check_api_error(cudaLaunchCooperativeKernel((void*)sum_array,\n",
        "                                              n_thread_blocks,\n",
        "                                              threads_per_block,\n",
        "                                              args));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(c, c_dev, sizeof(double) * n, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"sum = %f\\n\", c[0]);\n",
        "  assert(c[0] == n);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-056",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc -o cuda_sum_ans cuda_sum_ans.cu\n",
        "# nvc++ -Wall -o cuda_sum_ans cuda_sum_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_sum_ans cuda_sum_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-057",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_sum_ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-058",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 13. Visualizing threads executing on the device",
        "\n",
        "* When you call a kernel (function f) with\n",
        "```\n",
        "f<<<nb,bs>>>();\n",
        "```\n",
        "it creates (_nb * bs_) CUDA threads.\n",
        "\n",
        "* More precisely, it creates _nb_ thread blocks, each of which has _bs_ CUDA threads.\n",
        "\n",
        "* The following code is a program that records how threads are executed on GPU.\n",
        "\n",
        "* It creates many threads repeating a trivial (useless) computation x = a * x + b many times.\n",
        "\n",
        "* Each thread occasionally records the clock to record when and where these threads progress over time.\n",
        "\n",
        "* Specifically,\n",
        "\n",
        "```\n",
        "./cuda_sched_rec NTHREADS THREAD_BLOCK_SZ N M \n",
        "```\n",
        "\n",
        "creates approximately NTHREADS threads, with THREAD_BLOCK_SZ threads in each thread block (the number of threads is not exactly NTHREADS when it is not a multiple of THREAD_BLOCK_SZ).\n",
        "\n",
        "  * Each thread repeats x = A x + B, ($N \\times M$) times.\n",
        "  * Each thread records the clock $N$ times (every $M$ iterations).\n",
        "\n",
        "* At the end of execution, it dumps the results in the following format for each line.\n",
        "\n",
        "```\n",
        "thread=<idx> x=<ans> sm0=<starting SM> sm1=<ending SM> t0 t1 t2 ... t_{n-1}\n",
        "```\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-039",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_sched_rec.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "// error check utility (check_api_error and check_launch_error)\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "// record of execution\n",
        "typedef long long int llint;\n",
        "typedef struct {\n",
        "  double x;                     // a (meaningless) answer \n",
        "  uint sm0;                     // SM on which a thread got started\n",
        "  uint sm1;                     // SM on which a thread ended (MUST BE = sm0; just to verify that)\n",
        "} record_t;\n",
        "\n",
        "/* this thread repeats x = a x + b (N * M) times.\n",
        "   it records the clock N times (every M iterations of x = a x + b)\n",
        "   to array T.\n",
        "   final result of x = a x + b, as well as SM each thread was executed\n",
        "   on are recorded to R. */\n",
        "__global__ void cuda_thread_fun(double a, double b, record_t * R,\n",
        "                                llint * T, llint n, llint m,\n",
        "                                int nthreads) {\n",
        "  // my thread index\n",
        "  int idx      = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (idx >= nthreads) return;\n",
        "  // initial value (not important)\n",
        "  double x = idx;\n",
        "  // where clocks are recorded\n",
        "  T = &T[idx * n];\n",
        "  // record starting SM\n",
        "  R[idx].sm0 = get_smid();\n",
        "  // main thing. repeat a x + b many times,\n",
        "  // occasionally recording the clock\n",
        "  for (long i = 0; i < n; i++) {\n",
        "    T[i] = clock64();\n",
        "    for (long j = 0; j < m; j++) {\n",
        "      x = a * x + b;\n",
        "    }\n",
        "  }\n",
        "  // record ending SM (must be = sm0)\n",
        "  R[idx].sm1 = get_smid();\n",
        "  // record result, just so that the computation is not\n",
        "  // eliminated by the compiler\n",
        "  R[idx].x = x;\n",
        "}\n",
        "\n",
        "/* usage\n",
        "   ./cuda_sched NTHREADS THREAD_BLOCK_SZ N M S A B\n",
        "\n",
        "   creates about NTHREADS threads, with THREAD_BLOCK_SZ\n",
        "   threads in each thread block. \n",
        "   each thread repeats x = A x + B (N * M) times.\n",
        "\n",
        "   S is the shared memory allocated for each thread block\n",
        "   (just to control the number of thread blocks simultaneously\n",
        "   scheduled on an SM). shared memory is not actually used at all.\n",
        " */\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  int nthreads        = (argc > i ? atoi(argv[i])  : 100);  i++;\n",
        "  int thread_block_sz = (argc > i ? atoi(argv[i])  : 64);   i++;\n",
        "  llint n             = (argc > i ? atoll(argv[i]) : 100);  i++;\n",
        "  llint m             = (argc > i ? atoll(argv[i]) : 100);  i++;\n",
        "  int D               = (argc > i ? atoll(argv[i]) : 1);    i++;\n",
        "  int shm_sz          = (argc > i ? atoi(argv[i])  : 0);    i++;\n",
        "  double a            = (argc > i ? atof(argv[i])  : 0.99); i++;\n",
        "  double b            = (argc > i ? atof(argv[i])  : 1.00); i++;\n",
        "\n",
        "  // get the required number of thread blocks\n",
        "  int n_thread_blocks = (nthreads + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  // allocate record_t array (both on host and device)\n",
        "  long R_sz = sizeof(record_t) * nthreads;\n",
        "  record_t * R = (record_t *)calloc(R_sz, 1);\n",
        "  record_t * R_dev;\n",
        "  check_api_error(cudaMalloc(&R_dev, R_sz));\n",
        "  check_api_error(cudaMemcpy(R_dev, R, R_sz, cudaMemcpyHostToDevice));\n",
        "\n",
        "  // allocate clock array (both on host and device)\n",
        "  long T_sz = sizeof(llint) * n * nthreads;\n",
        "  llint * T = (llint *)calloc(T_sz, 1);\n",
        "  llint * T_dev;\n",
        "  check_api_error(cudaMalloc(&T_dev, T_sz));\n",
        "  check_api_error(cudaMemcpy(T_dev, T, T_sz, cudaMemcpyHostToDevice));\n",
        "\n",
        "  // call the kernel\n",
        "  int shm_elems = shm_sz / sizeof(double);\n",
        "  int shm_size = shm_elems * sizeof(double);\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz,shm_size>>>\n",
        "                      (a, b, R_dev, T_dev, n, m, nthreads)));\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // get back the results and clocks\n",
        "  check_api_error(cudaMemcpy(R, R_dev, R_sz, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaMemcpy(T, T_dev, T_sz, cudaMemcpyDeviceToHost));\n",
        "  // dump the for visualization\n",
        "  long k = 0;\n",
        "  for (long idx = 0; idx < nthreads; idx++) {\n",
        "    printf(\"thread=%ld x=%f sm0=%u sm1=%u\", idx, R[idx].x, R[idx].sm0, R[idx].sm1);\n",
        "    for (long i = 0; i < n; i++) {\n",
        "      printf(\" %lld\", T[k]);\n",
        "      k++;\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-059",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Read the code carefully and understand what it is doing.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-040",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc --generate-code arch=compute_80,code=sm_80 -o cuda_sched_rec cuda_sched_rec.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-041",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_sched_rec 64 32 10 100 | head -10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-060",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 14. Visualization",
        "\n",
        "* The following python code parses and visualizes the output of cuda_sched_rec.\n",
        "* The code is shown below for your information; you don't have to understand how it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-061",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Let's visualize a few configurations.\n",
        "\n",
        "## 14-1. one thread"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-042",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_sched_rec 1 1 100 1000 > cs_1_1.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-043",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "import cuda_sched_vis\n",
        "cuda_sched_vis.cuda_sched_plt([\"cs_1_1.dat\"], start_t=0, end_t=float(\"inf\"), start_thread=0, end_thread=float(\"inf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-062",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* you can change `start_t` and `end_t` to zoom into a narrower time interval and change `start_thread` and `end_thread` to zoom into a range of threads\n",
        "* or, you can open `sched.svg` generated along with the visualization and magnify anywhere you want to look into, either by the browser or any SVG viewer on your PC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-063",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 14-2. $N$ thread blocks $\\times$ 1 thread/block",
        "\n",
        "* play with changing $N$ to other values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-044",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "N=150\n",
        "./cuda_sched_rec ${N} 1 100 1000 > cs_N_1.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-045",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "import cuda_sched_vis\n",
        "cuda_sched_vis.cuda_sched_plt([\"cs_N_1.dat\"], start_t=0, end_t=float(\"inf\"), start_thread=0, end_thread=float(\"inf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-064",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Increase $N$ and observe when the execution time (the time at the right end of the graph) starts to increase.\n",
        "* Even in that case, all $N$ threads appear to be executing simultaneously (not one after another).\n",
        "* That is, _hardware_ interleaves execution of these threads, rapidly switching from one to another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-065",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 14-3. 1 thread block $\\times$ $N$ threads/block",
        "\n",
        "* play with changing $N$ to other values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-046",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "N=150\n",
        "./cuda_sched_rec ${N} ${N} 100 1000 > cs_N_N.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-047",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "import cuda_sched_vis\n",
        "cuda_sched_vis.cuda_sched_plt([\"cs_N_N.dat\"], start_t=0, end_t=float(\"inf\"), start_thread=0, end_thread=float(\"inf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-066",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Observe that they are always executed on the same SM. You are not utilizing multiple SMs at all.\n",
        "\n",
        "* There is a hardwired limit on the number of threads per block. Try to find it and then confirm it with Google.\n",
        "\n",
        "* When increasing $N$, find out when the execution time starts to increase. Why doesn't it immediately increase with $N$&gt;1?\n",
        "\n",
        "* With a modest value of $N$ (say 100), zoom in at either end of the execution and observe whether there is _any_ difference on when they started or finished execution.  If you look carefully, you will notice that a number of consecutive threads start and end _exactly the same clock_.  Those threads are called a _warp_ and they share an instruction pointer.  It is very analogous to SIMD instruction found in CPUs that apply the same operation on multiple operands.  Guess the number of threads of a warp from the experimental results and confirm it by Google."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-067",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 14-4. many thread blocks $\\times$ many threads/block",
        "\n",
        "* play with changing $N$ and $B$ to other values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-048",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "N=150\n",
        "B=64\n",
        "./cuda_sched_rec ${N} ${B} 100 1000 > cs_N_B.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-049",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "import cuda_sched_vis\n",
        "cuda_sched_vis.cuda_sched_plt([\"cs_N_B.dat\"], start_t=0, end_t=float(\"inf\"), start_thread=0, end_thread=float(\"inf\"), show_every=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-068",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* `show_every` parameter specifies that only visualize every this number of threads\n",
        "  * it reduces the time to visualize when the number of threads is so large\n",
        "* Try to find the maximum number of threads that does not increase the execution time.\n",
        "  * use `show_every=32` to reduce the time for visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-069",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 15. Thread blocks",
        "\n",
        "A thread block is the unit of dispatching to a streaming multiprocessor (SM), which is like a physical core of a CPU.  Threads within a thread block are always dispatched together to the same SM and once dispatched stay on the same SM until finished.\n",
        "\n",
        "* see [CUDA C++ Programming Guide: A Scalable Programming Model](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#scalable-programming-model)\n",
        "\n",
        "* An SM is a highly multithreaded processor, which can accommodate many threads at the same time and interleave them  by hardware.  For example, it can easily hold, say, 500 threads and interleave their execution without involving software.  In terms of hardware capability, it is somewhat similar to simultaneous multithreading (SMT) of CPUs.  The degree of multithreading is very different, however; Intel CPUs normally support only two hardware threads (virtual cores) on each physical core.  Moreover, software (either operating system or user-level software) needs to designate which virtual core you want to run a thread on.  In a sense, CPU exposes each virtual core as a single-threaded machine.  If you put more than one OpenMP (OS-level) thread on the same virtual core, software (i.e., OS) switches between them from time to time.  A streaming multiprocessor of a GPU, in contrast, is a machine that literally takes many threads and concurrently executes them by hardware.  Determining the SM a thread block executes on is done by hardware.\n",
        "\n",
        "* How many thread blocks are scheduled on an SM at the same time?  It depends; it depends on how much \"resources\" a single thread block requires.  Here, \"resources\" mean two things.\n",
        "1. registers\n",
        "1. shared memory (see below)\n",
        "* _Registers_ are used for holding local variables and intermediate results of computation.  How many registers a thread block uses is not something you can reliably determine by looking at your code; it depends on the code generated by the compiler.  You can know it by passing `-Xptxas -v` to nvcc and looking at the compiler message.\n",
        "\n",
        "* _Shared memory_ is a scratch-pad memory only shared within a single thread block.  Physically, you can consider it to be a small fast memory attached to each SM.  The name \"shared memory\" is clearly a misnomer; ordinary memory you get by `cudaMalloc` _is_ shared by all threads (called \"global memory\").  In contrast, shared memory is, contrary to its name, shared only among threads within a single thread block.  \"Local memory\" (as opposed to global memory) would have been a better name for it, IMO.\n",
        "\n",
        "* Both registers and shared memory for a thread block are kept on physical registers/memory of an SM throughout the lifetime of the thread block.  Thus, accommodating a larger number of thread blocks at the same time requires a proportionally larger amount of registers/shared memory, which is subject to the physical resource limit of an SM.\n",
        "\n",
        "* Each SM has the following physical resources.\n",
        "\n",
        "|       | registers      |  shared memory  |\n",
        "|-------|----------------|-----------------|\n",
        "|Pascal | 32 bit x 65536 |  64KB           |\n",
        "|Volta  | 32 bit x 65536 |  up to 96KB (*) |\n",
        "|Ampere | 32 bit x 65536 |  up to 163KB    |\n",
        "\n",
        "(*) configurable subject to L1 cache + shared memory <= 128KB and shared memory <= 96KB\n",
        "\n",
        "* [Pascal Tuning Guide: Occupancy](https://docs.nvidia.com/cuda/pascal-tuning-guide/index.html#sm-occupancy)\n",
        "* [Volta Tuning Guide: Occupancy](https://docs.nvidia.com/cuda/volta-tuning-guide/index.html#sm-occupancy)\n",
        "* [NVIDIA Ampere GPU Architecture Tuning Guide: Occupancy](https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#sm-occupancy)\n",
        "\n",
        "* By default, a thread does not use shared memory at all.\n",
        "\n",
        "* Let's observe how many registers a thread uses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-050",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc --generate-code arch=compute_80,code=sm_80 -Xptxas -v -o cuda_sched_rec cuda_sched_rec.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-070",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Since the computation is very simple, register usage will not be a limiting factor for this computation.\n",
        "* Also, since it does not use shared memory at all, it won't be a limiting factor either.\n",
        "* Only the hardwired limit is the limiting factor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-071",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 16. Shared memory",
        "\n",
        "* Let's use shared memory to observe how it affects the number of thread blocks simultaneously executed.\n",
        "You specify the size of shared memory per thread block via the third parameter of kernel call, like this.\n",
        "\n",
        "```\n",
        "f<<<nb,bs,S>>>();\n",
        "```\n",
        "\n",
        "* The above kernel launch statement specifies that $S$ bytes of shared memory should be allocated to _each thread block_.  Each SM can therefore execute only up to (SHARED_MEMORY_SIZE_PER_SM / $S$) thread blocks simultaneously.\n",
        "\n",
        "* You can get a pointer to the part of the shared memory allocated to each thread via the following strange syntax within your kernel function, though it is not necessary in our current experiment.\n",
        "\n",
        "```\n",
        "extern __shared__ T shmem[];\n",
        "```\n",
        "\n",
        "* With that, `shmem` points to the start of the shared memory for the thread block.  The name can be arbitrary.\n",
        "\n",
        "* `cuda_sched_rec.cu` is already written to take the size of the shared memory per thread block as a parameter.\n",
        "\n",
        "* Let's allocate 32KB for each thread block; then, on Ampere, only up to three thread blocks (163KB/32KB) can be executed simultaneously.\n",
        "\n",
        "* The following creates 100 thread blocks (in order to avoid creating too many threads, it will set the thread per block to an unusual value of one)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-051",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "N=150\n",
        "S=$((32 * 1024))\n",
        "./cuda_sched_rec ${N} 1 100 1000 ${S} > cs_N_1_S.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-072",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Before visualizing it, imagine what it is like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-052",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "import cuda_sched_vis\n",
        "cuda_sched_vis.cuda_sched_plt([\"cs_N_1_S.dat\"], start_t=0, end_t=float(\"inf\"), start_thread=0, end_thread=float(\"inf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-073",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Play with changing $N$ above; predict when thread blocks start executing not simultaneously (one after another) and confirm it by the experiment (hint: Ampere has 108 streaming multiprocessors).\n",
        "* Change $S$ and see how it affects the above threshold value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-074",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 17. Warp",
        "\n",
        "* Consecutively numbered 32 threads within a thread block makes a _warp_ and they can execute only one same instruction at a time.\n",
        "* That is, it's not possible, within a single cycle, for some threads to execute an instruction A while others in the same warp execute another instruction B.  All the GPU can do is simply to keep some threads from executing instructions that they should not execute.\n",
        "* A typical example is an \"if\" statement. e.g.,\n",
        "```\n",
        "if (thread_idx % 2 == 0) {\n",
        "  A;\n",
        "} else {\n",
        "  B;\n",
        "}\n",
        "```\n",
        "* If there are _any_ thread executing A and _any_ thread executing B within a warp, the time the warp takes is the time to execute A _plus_ the time to execute B.\n",
        "* An important performance implication is you'd better not have threads branching differently within the same warp.\n",
        "\n",
        "* Change the following code as follows.\n",
        "  * it takes an additional command line parameter D\n",
        "  * each thread executes the loop\n",
        "```\n",
        "      for (long j = 0; j < m; j++) {\n",
        "        x = a * x + b;\n",
        "      }\n",
        "```\n",
        "when and only when (idx / D) is an odd number.\n",
        "  * for example, if D is 1, then all even-numbered threads execute the loop and all odd-numbered threads do not execute it\n",
        "  * if D is 32, for example, (idx / D) is essentially the \"warp index\"; even-numbered warps execute the loop and odd-numbered warps skip it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-053",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_sched_rec_warp.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "// error check utility (check_api_error and check_launch_error)\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "// record of execution\n",
        "typedef long long int llint;\n",
        "typedef struct {\n",
        "  double x;                     // a (meaningless) answer \n",
        "  uint sm0;                     // SM on which a thread got started\n",
        "  uint sm1;                     // SM on which a thread ended (MUST BE = sm0; just to verify that)\n",
        "} record_t;\n",
        "\n",
        "/* this thread repeats x = a x + b (N * M) times.\n",
        "   it records the clock N times (every M iterations of x = a x + b)\n",
        "   to array T.\n",
        "   final result of x = a x + b, as well as SM each thread was executed\n",
        "   on are recorded to R. */\n",
        "__global__ void cuda_thread_fun(double a, double b, record_t * R,\n",
        "                                llint * T, llint n, llint m,\n",
        "                                int D,\n",
        "                                int nthreads) {\n",
        "  // my thread index\n",
        "  int idx      = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (idx >= nthreads) return;\n",
        "  // initial value (not important)\n",
        "  double x = idx;\n",
        "  // where clocks are recorded\n",
        "  T = &T[idx * n];\n",
        "  // record starting SM\n",
        "  R[idx].sm0 = get_smid();\n",
        "  // main thing. repeat a x + b many times,\n",
        "  // occasionally recording the clock\n",
        "  for (long i = 0; i < n; i++) {\n",
        "    T[i] = clock64();\n",
        "    if ((idx / D) % 2 == 0) {\n",
        "      for (long j = 0; j < m; j++) {\n",
        "        x = a * x + b;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  // record ending SM (must be = sm0)\n",
        "  R[idx].sm1 = get_smid();\n",
        "  // record result, just so that the computation is not\n",
        "  // eliminated by the compiler\n",
        "  R[idx].x = x;\n",
        "}\n",
        "\n",
        "/* usage\n",
        "   ./cuda_sched NTHREADS THREAD_BLOCK_SZ N M S A B\n",
        "\n",
        "   creates about NTHREADS threads, with THREAD_BLOCK_SZ\n",
        "   threads in each thread block. \n",
        "   each thread repeats x = A x + B (N * M) times.\n",
        "\n",
        "   S is the shared memory allocated for each thread block\n",
        "   (just to control the number of thread blocks simultaneously\n",
        "   scheduled on an SM). shared memory is not actually used at all.\n",
        " */\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  int nthreads        = (argc > i ? atoi(argv[i])  : 100);  i++;\n",
        "  int thread_block_sz = (argc > i ? atoi(argv[i])  : 64);   i++;\n",
        "  llint n             = (argc > i ? atoll(argv[i]) : 100);  i++;\n",
        "  llint m             = (argc > i ? atoll(argv[i]) : 100);  i++;\n",
        "  int D               = (argc > i ? atoll(argv[i]) : 1);    i++;\n",
        "  int shm_sz          = (argc > i ? atoi(argv[i])  : 0);    i++;\n",
        "  double a            = (argc > i ? atof(argv[i])  : 0.99); i++;\n",
        "  double b            = (argc > i ? atof(argv[i])  : 1.00); i++;\n",
        "\n",
        "  // get the required number of thread blocks\n",
        "  int n_thread_blocks = (nthreads + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  // allocate record_t array (both on host and device)\n",
        "  long R_sz = sizeof(record_t) * nthreads;\n",
        "  record_t * R = (record_t *)calloc(R_sz, 1);\n",
        "  record_t * R_dev;\n",
        "  check_api_error(cudaMalloc(&R_dev, R_sz));\n",
        "  check_api_error(cudaMemcpy(R_dev, R, R_sz, cudaMemcpyHostToDevice));\n",
        "\n",
        "  // allocate clock array (both on host and device)\n",
        "  long T_sz = sizeof(llint) * n * nthreads;\n",
        "  llint * T = (llint *)calloc(T_sz, 1);\n",
        "  llint * T_dev;\n",
        "  check_api_error(cudaMalloc(&T_dev, T_sz));\n",
        "  check_api_error(cudaMemcpy(T_dev, T, T_sz, cudaMemcpyHostToDevice));\n",
        "\n",
        "  // call the kernel\n",
        "  int shm_elems = shm_sz / sizeof(double);\n",
        "  int shm_size = shm_elems * sizeof(double);\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz,shm_size>>>\n",
        "                      (a, b, R_dev, T_dev, n, m, D, nthreads)));\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  // get back the results and clocks\n",
        "  check_api_error(cudaMemcpy(R, R_dev, R_sz, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaMemcpy(T, T_dev, T_sz, cudaMemcpyDeviceToHost));\n",
        "  // dump the for visualization\n",
        "  long k = 0;\n",
        "  for (long idx = 0; idx < nthreads; idx++) {\n",
        "    printf(\"thread=%ld x=%f sm0=%u sm1=%u\", idx, R[idx].x, R[idx].sm0, R[idx].sm1);\n",
        "    for (long i = 0; i < n; i++) {\n",
        "      printf(\" %lld\", T[k]);\n",
        "      k++;\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-054",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc --generate-code arch=compute_80,code=sm_80 -o cuda_sched_rec_warp cuda_sched_rec_warp.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-075",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Execute the code with various D's (and perhaps other parameters) to visualize the effect of warps and its performance implication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-055",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "N=256\n",
        "./cuda_sched_rec_warp ${N} 32 100 1000 1 > cs_warp.dat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-056",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "import cuda_sched_vis\n",
        "cuda_sched_vis.cuda_sched_plt([\"cs_warp.dat\"], start_t=0, end_t=float(\"inf\"), start_thread=0, end_thread=float(\"inf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-076",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 8 :  Putting them together: calculating an integral</font>",
        "\n",
        "* Write a CUDA program that calculates\n",
        "\n",
        "$$ \\int_0^1 \\int_0^1 \\sqrt{1 - x^2 - y^2}\\,dx\\,dy $$\n",
        "\n",
        "* mathematical note: consider the integrand to be zero outside $1 - x^2 - y^2 \\geq 0$\n",
        "\n",
        "* Write a CUDA kernel that computes the integrand on a single point\n",
        "* And launch it with as many threads as the number of points you compute the integrand at\n",
        "* The result should be close to $\\pi/6$ (1/8 of the volume of the unit ball)\n",
        "* Play with the number of infinitesimal intervals for integration and the number of threads so that you can observe a speedup\n",
        "* Measure the time not just for the entire computation, but the time of each step including cudaMalloc, cudaMemcpy to initialize variables on the device, kernel and cudaMemcpy to get the result back\n",
        "* Try atomicAdd as well as reduction \n",
        "* Play with unified memory also"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-057",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_integral.cu\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-058",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_integral cuda_integral.cu\n",
        "# nvc++ -Wall -o cuda_integral cuda_integral.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_integral cuda_integral.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-059",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_integral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-077",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_integral_ans.cu\n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "double cur_time() {\n",
        "  struct timespec tp[1];\n",
        "  clock_gettime(CLOCK_REALTIME, tp);\n",
        "  return tp->tv_sec + tp->tv_nsec * 1.0e-9;\n",
        "}\n",
        "\n",
        "__global__ void cuda_thread_fun(int n, double xa, double ya, double dx, double dy, double * sp) {\n",
        "  int i          = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int j          = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "  if (i < n && j < n) {\n",
        "    double x = xa + i * dx;\n",
        "    double y = ya + j * dy;\n",
        "    double z2 = 1 - x * x - y * y;\n",
        "    if (z2 > 0) {\n",
        "      atomicAdd(sp, sqrt(z2) * dx * dy);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  double xa = 0.0;\n",
        "  double xb = 1.0;\n",
        "  double ya = 0.0;\n",
        "  double yb = 1.0;\n",
        "  int n = 10000;\n",
        "  double dx = (xb - xa) / n;\n",
        "  double dy = (yb - ya) / n;\n",
        "\n",
        "  // thread configuration\n",
        "  int nx                = n;\n",
        "  int ny                = n;\n",
        "  int thread_block_sz_x = (argc > 1 ? atoi(argv[1]) : 8);\n",
        "  int thread_block_sz_y = thread_block_sz_x;\n",
        "  int n_thread_blocks_x = (nx + thread_block_sz_x - 1) / thread_block_sz_x;\n",
        "  int n_thread_blocks_y = (ny + thread_block_sz_y - 1) / thread_block_sz_y;\n",
        "\n",
        "  double s = 0.0;\n",
        "  double * s_dev;\n",
        "  double t0 = cur_time();\n",
        "  check_api_error(cudaMalloc(&s_dev, sizeof(double)));\n",
        "  double t1 = cur_time();\n",
        "  check_api_error(cudaMemcpy(s_dev, &s, sizeof(double), cudaMemcpyHostToDevice));\n",
        "  double t2 = cur_time();\n",
        "  \n",
        "  dim3 nb(n_thread_blocks_x, n_thread_blocks_y);\n",
        "  dim3 tpb(thread_block_sz_x, thread_block_sz_y);\n",
        "  check_launch_error((cuda_thread_fun<<<nb,tpb>>>(n, xa, ya, dx, dy, s_dev)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  double t3 = cur_time();\n",
        "  \n",
        "  check_api_error(cudaMemcpy(&s, s_dev, sizeof(double), cudaMemcpyDeviceToHost));\n",
        "  double t4 = cur_time();\n",
        "  \n",
        "  printf(\"ans = %.9f\\n\", s);\n",
        "  printf(\" cudaMalloc  : %f sec\\n\", t1 - t0);\n",
        "  printf(\" host -> dev : %f sec\\n\", t2 - t1);\n",
        "  printf(\" kernel      : %f sec\\n\", t3 - t2);\n",
        "  printf(\" host <- dev : %f sec\\n\", t4 - t3);\n",
        "  printf(\"---------------------------\\n\");\n",
        "  printf(\"total        : %f sec\\n\", t4 - t0);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-078",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc -o cuda_integral_ans cuda_integral_ans.cu\n",
        "# nvc++ -Wall -o cuda_integral_ans cuda_integral_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_integral_ans cuda_integral_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-079",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_integral_ans"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "SoS",
      "language": "sos",
      "name": "sos"
    },
    "language_info": {
      "codemirror_mode": "sos",
      "file_extension": ".sos",
      "mimetype": "text/x-sos",
      "name": "sos",
      "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
      "pygments_lexer": "sos"
    },
    "sos": {
      "kernels": [
        [
          "Bash",
          "bash",
          "bash",
          "",
          "shell"
        ],
        [
          "C",
          "c_kernel",
          "c",
          "",
          ""
        ],
        [
          "Go",
          "gophernotes",
          "go",
          "",
          ""
        ],
        [
          "Julia 1.10.2",
          "julia-1.10",
          "julia",
          "",
          ""
        ],
        [
          "OCaml default",
          "ocaml-jupyter",
          "OCaml",
          "",
          "text/x-ocaml"
        ],
        [
          "Python 3 (ipykernel)",
          "python3",
          "python3",
          "",
          {
            "name": "ipython",
            "version": 3
          }
        ],
        [
          "Rust",
          "rust",
          "rust",
          "",
          ""
        ]
      ],
      "panel": {
        "displayed": true,
        "height": 0
      },
      "version": "0.23.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}