{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-001",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 1. CUDA Programming Tutorial and Hands-on",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-002",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "Enter your name and student ID.\n",
        "\n",
        " * Name:\n",
        " * Student ID:\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-003",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 2. CUDA",
        "\n",
        "* [CUDA](https://docs.nvidia.com/cuda/index.html) is an extension to C++ specific to NVIDIA GPUs\n",
        "* It is the most basic, native programming model for NVIDIA GPUs\n",
        "\n",
        "# 3. Compilers",
        "\n",
        "* We use [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) (`nvcc`) for CUDA compilers\n",
        "* [LLVM ver. 18.1.8](https://llvm.org/) (`clang` and `clang++`) and NVIDA's C/C++ compilers (`nvc` and `nvc++`) we used for OpenMP also support CUDA, but they fail to compile some of our code, so we stick to more traditional `nvcc`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-004",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 3-1. Set up NVIDIA CUDA and HPC SDK",
        "\n",
        "Execute this before you use NVIDIA HPC SDK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-005",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/24.9/compilers/bin:$PATH\n",
        "export PATH=/usr/local/cuda/bin:$PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-006",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Check if it works\n",
        "  * make sure the full path of nvcc is shown as `/usr/local/...`, not `/opt/nvidia/...`\n",
        "* We do not recommend nvc/nvc++ for this exercise, but you might give them a try if you like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-007",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which nvcc\n",
        "which nvc\n",
        "which nvc++\n",
        "nvcc --version\n",
        "nvc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-008",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 3-2. LLVM",
        "\n",
        "* We do not recommend it for this exercise, but you might give them a try if you like\n",
        "* Execute this before you use LLVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-009",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/home/share/llvm/bin:$PATH\n",
        "export LD_LIBRARY_PATH=/home/share/llvm/lib:/home/share/llvm/lib/x86_64-unknown-linux-gnu:$LD_LIBRARY_PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-010",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Check if it works (check if full paths of clang/clang++ are shown)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-011",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which clang\n",
        "which clang++\n",
        "clang --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-012",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 4. Check host and GPU",
        "\n",
        "* First check if you are using the right host, tauleg000, <font color=\"red\">not taulec</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-013",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "hostname\n",
        "hostname | grep tauleg || echo \"Oh, you are not on the right host, access https://tauleg000.zapto.org/ instead\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-014",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Check if GPU is alive by nvidia-smi\n",
        "* Do `nvidia-smi --help` or see manual (`man nvidia-smi` on terminal) for more info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-015",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-016",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 5. Compiling and running CUDA programs",
        "\n",
        "## 5-1. With nvcc (NVIDIA HPC SDK CUDA compiler)",
        "\n",
        "* Give a source file `.cu` extension or give `--x cu` option to indicate it is a CUDA source file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-001",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int nthreads = gridDim.x * blockDim.x;\n",
        "  if (i < n) {\n",
        "    printf(\"hello I am CUDA thread %d out of %d\\n\", i, nthreads);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 100);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  // launch a kernel\n",
        "  cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(n);\n",
        "  // wait for them to complete\n",
        "  cudaDeviceSynchronize();\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-002",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello cuda_hello.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-003",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* You should see 100 lines of \"hello I am CUDA thread ??? out of 128\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-018",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Alternatively, you can have a source file with an ordinary C++ extension `.cc` (or `.cpp`) and give `-x cu`.\n",
        "* It is useful when you want to have a single source file for OpenMP and CUDA programs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-019",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "ln -sf cuda_hello.cu cuda_hello.cc\n",
        "nvcc -o cuda_hello -x cu cuda_hello.cc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-020",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_hello"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-021",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 5-2. With nvc++ (NVIDIA HPC SDK C++ compiler)",
        "\n",
        "* Just to demonstrate `nvc++` supports CUDA, too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-004",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvc++ -Wall -o cuda_hello cuda_hello.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-022",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvc++ -Wall -o cuda_hello -x cu cuda_hello.cc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-023",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 5-3. With clang++ (LLVM)",
        "\n",
        "* Just to demonstrate `clang++` supports CUDA, too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-005",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "clang++ -Wall -o cuda_hello cuda_hello.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-024",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "ln -sf cuda_hello.cu cuda_hello.cc\n",
        "clang++ -Wall -o cuda_hello -x cu cuda_hello.cc -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-025",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 6. CUDA kernel",
        "\n",
        "* The most basic concept of CUDA programming is a _CUDA kernel_\n",
        "* Syntactically, a CUDA kernel is a `void` function with `__global__` keyword attached to it\n",
        "```\n",
        "__global__ void cuda_thread_fun(int n) { ... }\n",
        "```\n",
        "* A CUDA kernel describes what a _single_ CUDA thread does\n",
        "* You launch a number of CUDA threads all executing the same kernel by \n",
        "```\n",
        "kernel_func<<<num_of_blocks,num_of_threads_per_block>>>(...);\n",
        "```\n",
        "* We have already seen this in the above code\n",
        "* See [2. Programming model](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model) section for reference\n",
        "\n",
        "## 6-1. <font color=\"red\">You'd better always check errors</font>",
        "\n",
        "* It's not only CUDA programming in which you are strongly advised to check errors after each operation that could potentially go wrong\n",
        "* Just like many C programming APIs (unlike Python scripting, for example), calling CUDA APIs and launching CUDA kernels silently return if something went wrong\n",
        "* You could save a huge amount of time by checking errors \n",
        "  * every time you launch a CUDA kernel and\n",
        "  * every time you call a CUDA API\n",
        "\n",
        "* Here is the same piece of code with checking errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-006",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello_chk.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "/*\n",
        "  you'd better spend time on making sure you always check errors ...\n",
        "*/\n",
        "\n",
        "void check_api_error_(cudaError_t e,\n",
        "                      const char * msg, const char * file, int line) {\n",
        "  if (e) {\n",
        "    fprintf(stderr, \"%s:%d:error: %s %s\\n\",\n",
        "            file, line, msg, cudaGetErrorString(e));\n",
        "    exit(1);\n",
        "  }\n",
        "}\n",
        "\n",
        "#define check_api_error(e) check_api_error_(e, #e, __FILE__, __LINE__)\n",
        "\n",
        "void check_launch_error_(const char * msg, const char * file, int line) {\n",
        "  cudaError_t e = cudaGetLastError();\n",
        "  if (e) {\n",
        "    fprintf(stderr, \"%s:%d:error: %s %s\\n\",\n",
        "            file, line, msg, cudaGetErrorString(e));\n",
        "    exit(1);\n",
        "  }\n",
        "}\n",
        "\n",
        "#define check_launch_error(exp) do { exp; check_launch_error_(#exp, __FILE__, __LINE__); } while (0)\n",
        "\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int nthreads = gridDim.x * blockDim.x;\n",
        "  if (i < n) {\n",
        "    printf(\"hello I am CUDA thread %d out of %d\\n\", i, nthreads);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 100);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-007",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello_chk cuda_hello_chk.cu\n",
        "# nvc++ -Wall -o cuda_hello_chk cuda_hello_chk.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_hello_chk cuda_hello_chk.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-008",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_chk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-026",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* I factored out the error-checking code into a header file `\"cuda_util.h\"` and included it in the directory (check it from the left menu)\n",
        "* The following code is a more concise version using the header file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-009",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello_hdr_chk.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int nthreads = gridDim.x * blockDim.x;\n",
        "  if (i < n) {\n",
        "    printf(\"hello I am CUDA thread %d out of %d\\n\", i, nthreads);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 100);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "  printf(\"%d threads/block * %d blocks\\n\", thread_block_sz, n_thread_blocks);\n",
        "\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-010",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello_hdr_chk cuda_hello_hdr_chk.cu\n",
        "# nvc++ -Wall -o cuda_hello_hdr_chk cuda_hello_hdr_chk.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_hello_hdr_chk cuda_hello_hdr_chk.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-011",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_hdr_chk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-027",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 7. The number of CUDA threads launched",
        "\n",
        "* You specify the number of threads launched by the two parameters in <<<...,...>>>, like\n",
        "```\n",
        "kernel_func<<<num_of_blocks,num_of_threads_per_block>>>(...);\n",
        "```\n",
        "\n",
        "* It will create (num_of_blocks * num_of_threads_per_block) threads in total.\n",
        "* More precisely, it creates num_of_blocks _thread blocks_, each of which has num_of_threads_per_block threads.\n",
        "* It is natural to wonder why you need to specify two parameters instead of just one parameter (the total number of threads) and how to choose num_of_threads_per_block.\n",
        "* For now, just know that a thread block is the unit of scheduling\n",
        "  * A GPU device fetches a single block at a time and dispatches it to a particular streaming multiprocessor (SM)\n",
        "  * Remember that a single SM is like a CPU core; a single GPU device has a number of SMs just like a single CPU has a number of cores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-028",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 1 :  Change the number of threads per block</font>",
        "\n",
        "Change the arguments of the following command line in various ways and see what happens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-012",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_hdr_chk 10 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-029",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Answer for trivial work omitted</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-030",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 8. Thread ID",
        "\n",
        "## 8-1. One-dimensional ID",
        "\n",
        "* Just like OpenMP, CUDA provides a means for a thread to know its ID as well as the total number of threads launched together\n",
        "* They are obtained from builtin variables\n",
        "* Let's say you invoked a kernel with\n",
        "```\n",
        "f<<<12,34>>>(...);\n",
        "```\n",
        "you create 12 thread blocks having 34 threads each (408 threads in total).\n",
        " * `gridDim.x` gives the number of thread blocks ($= 12$)\n",
        " * `blockDim.x` gives the number of threads in a thread block ($= 34$)\n",
        "\n",
        "* note: \"grid\" is the CUDA terminology to mean all the launched thread blocks (a CUDA thread $\\in$ thread block $\\in$ the entire grid)\n",
        "\n",
        " * `blockIdx.x` gives the block ID within the grid ($\\in [0,12)$) \n",
        " * `threadIdx.x` gives the thread ID within a thread block ($\\in [0,34)$)\n",
        "* If you want to get a single thread ID between 0 to 407 and the total number of threads, you get them by\n",
        "```\n",
        "int idx      = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "int nthreads = gridDim.x * blockDim.x;\n",
        "```\n",
        "* You have seen them in the above example.\n",
        "\n",
        "* See [2.1 Kernels](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#kernels) for reference\n",
        "\n",
        "## 8-2. Two- or three-dimensional ID",
        "\n",
        "* Each of the above four variables can actually have up to three elements, allowing you to view blocks and threads within a block arranged in an one-, two- or three-dimensional space.  \n",
        "* You specify them accordingly when you call a kernel, for which you use a variable of type `dim3` instead of an integer, to specify up to three numbers\n",
        "\n",
        "* See [2.2 Thread Hierarchy](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy) for reference\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-013",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_hello_2d.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(int n) {\n",
        "  int x          = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int y          = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "  int nthreads_x = gridDim.x * blockDim.x;\n",
        "  int nthreads_y = gridDim.y * blockDim.y;\n",
        "  int g          = x + nthreads_y * y;\n",
        "  if (g < n) {\n",
        "    printf(\"hello I am CUDA thread (%d,%d) of (%d,%d)\\n\",\n",
        "           x, y, nthreads_x, nthreads_y);\n",
        "  }\n",
        "}\n",
        "\n",
        "int isqrt(int n) {\n",
        "  int i;\n",
        "  for (i = 0; i * i < n; i++) ;\n",
        "  return i;\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n                 = (argc > 1 ? atoi(argv[1]) : 40);\n",
        "  int nx                = isqrt(n);\n",
        "  int ny                = (n + nx - 1) / nx;\n",
        "  int thread_block_sz_x = (argc > 2 ? atoi(argv[2]) : 2);\n",
        "  int thread_block_sz_y = (argc > 3 ? atoi(argv[3]) : 3);\n",
        "  int n_thread_blocks_x = (nx + thread_block_sz_x - 1) / thread_block_sz_x;\n",
        "  int n_thread_blocks_y = (ny + thread_block_sz_y - 1) / thread_block_sz_y;\n",
        "  printf(\"(%d * %d) threads/block * (%d * %d) blocks\\n\",\n",
        "         thread_block_sz_x, thread_block_sz_y,\n",
        "         n_thread_blocks_x, n_thread_blocks_y);\n",
        "\n",
        "  dim3 nb(n_thread_blocks_x, n_thread_blocks_y);\n",
        "  dim3 tpb(thread_block_sz_x, thread_block_sz_y);\n",
        "  check_launch_error((cuda_thread_fun<<<nb,tpb>>>(n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-014",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_hello_2d cuda_hello_2d.cu\n",
        "# nvc++ -Wall -o cuda_hello_2d cuda_hello_2d.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_hello_2d cuda_hello_2d.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-015",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-031",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 2 :  Specify 2D thread blocks and grids</font>",
        "\n",
        "* Change the arguments of the following command line in various ways and see what happens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-016",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_hello_2d 40 2 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-032",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Answer for trivial work omitted</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-033",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 9. Passing data between host (CPU) and device (GPU)",
        "\n",
        "* GPU is a device separate from a host CPU\n",
        "* As such, CPU and GPU do not share memory; you need to explicitly pass data by calling APIs (this is changing but practically remains true for a while)\n",
        "* One simplest way to pass data from a host to device is arguments to a kernel function, but\n",
        "  * it cannot be used for device -&gt; host (recall that kernel functions are always void)\n",
        "  * it is limited to values passed by \"call-by-value\"; you cannot pass pointers along with values pointed to by them\n",
        "* For anything other than passing arguments by call-by-values, you should use `cudaMalloc` and `cudaMemcpy`\n",
        "\n",
        "* See [3.2.2. Device Memory](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory) for reference\n",
        "\n",
        "## 9-1. cudaMalloc",
        "\n",
        "```\n",
        "void * p;\n",
        "check_api_error(cudaMalloc(&p, size));\n",
        "```\n",
        "\n",
        "* allocates `size` bytes of memory on device and\n",
        "* returns an address valid on the device (not valid on the host) to variable `p`\n",
        "\n",
        "* remember that this function should be called on host; no functions are provided in CUDA API for CUDA threads to dynamically allocate memory along the way\n",
        "\n",
        "## 9-2. cudaMemcpy",
        "\n",
        "* host -&gt; device\n",
        "```\n",
        "check_api_error(cudaMemcpy(p_dev, p_host, size, cudaMemcpyHostToDevice));\n",
        "```\n",
        "\n",
        "* device -&gt; host\n",
        "```\n",
        "check_api_error(cudaMemcpy(p_host, p_dev, size, cudaMemcpyDeviceToHost));\n",
        "```\n",
        "\n",
        "* the first argument is always the destination\n",
        "* p_dev should be an address on device (i.e., that has been allocated by `cudaMalloc`)\n",
        "\n",
        "## 9-3. cudaFree",
        "\n",
        "```\n",
        "check_api_error(cudaFree(dev_p));\n",
        "```\n",
        "\n",
        "* frees memory allocated by cudaMalloc\n",
        "\n",
        "* The following code demonstrates how to get some results back to host using `cudaMalloc` and `cudaMemcpy`\n",
        "* Results show when each CUDA thread started executing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-017",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_memcpy.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  p[i] = clock64();\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  long long * c = (long long *)malloc(sizeof(long long) * n);\n",
        "  long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(long long) * n));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(c, c_dev, sizeof(long long) * n, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %lld\\n\", i, c[i]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-018",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_memcpy cuda_memcpy.cu\n",
        "# nvc++ -Wall -o cuda_memcpy cuda_memcpy.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_memcpy cuda_memcpy.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-019",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_memcpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-034",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 3 :  Get data back from GPU to CPU</font>",
        "\n",
        "* Change the arguments of the following command line in various ways and observe clock values printed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-020",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_memcpy 10 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-035",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Answer for trivial work omitted</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-036",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* You observe some threads record exactly the same clock value\n",
        "* What do you deduce from that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-021",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-037",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Example answer</font>_\n",
        "\n",
        "* Threads having 32 consecuive thread IDs report exactly the same clock value\n",
        "* It stems from the fact that those threads share an instruction pointer (execute the same instruction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-038",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 10. Unified Memory",
        "\n",
        "* with unified memory you do not have to call `cudaMemcpy` to move data between host and GPU\n",
        "* all you need to master is `cudaMallocManaged`, which you call in place of `cudaMalloc`\n",
        "* you get a pointer that is valid both on CPU and GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-039",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 4 :  Use Unified Memory</font>",
        "\n",
        "* Change the following program so that it uses `cudaMallocManaged` instead of `cudaMalloc`.  Make appropriate changes to other parts (e.g., remove unnecessary `cudaMemcpy`) so that it behaves similar to the original one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-022",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_malloc_managed.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  p[i] = i;\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  long long * c = (long long *)malloc(sizeof(long long) * n);\n",
        "  long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(long long) * n));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "\n",
        "  check_api_error(cudaMemcpy(c, c_dev, sizeof(long long) * n, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  \n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %lld\\n\", i, c[i]);\n",
        "  }\n",
        "\n",
        "  free(c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-023",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_malloc_managed cuda_malloc_managed.cu\n",
        "# nvc++ -Wall -o cuda_malloc_managed cuda_malloc_managed.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_malloc_managed cuda_malloc_managed.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-024",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_malloc_managed 10 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-040",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_malloc_managed.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  p[i] = i;\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 10);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 3);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  long long * c;\n",
        "  check_api_error(cudaMallocManaged(&c, sizeof(long long) * n));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "\n",
        "  \n",
        "  for (int i = 0; i < n; i++) {\n",
        "    printf(\"c[%d] = %lld\\n\", i, c[i]);\n",
        "  }\n",
        "\n",
        "  check_api_error(cudaFree(c));\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-041",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 11. CUDA device memory model",
        "\n",
        "* memory blocks allocated by `cudaMalloc` are visiable to (shared by) all threads and called _global memory_\n",
        "* they persist on device until you release them by cudaFree (or the process finishes), so they can be used not only to pass values between device and host, but also to pass values between different kernel calls (without moving values back and forth between host and device each time you call a kernel)\n",
        "\n",
        "* See [Memory Hierarchy](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy) for reference\n",
        "\n",
        "# 12. Race condition and atomic operation ",
        "\n",
        "* As threads launched in a single kernel call run concurrently, they are subject to the same race condition as OpenMP threads\n",
        "* That is, if two threads access the same variable (or the same array element) and at least one of them is a write, there is a race and the program almost certainly has a bug\n",
        "\n",
        "* In the following program, each thread increments a variable by one; it nevertheles does not print the number of threads launched and prints unpredictable results each time executed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-025",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_race.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(unsigned long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    *p = *p + 1;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 1000);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  unsigned long long c;\n",
        "  unsigned long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(unsigned long long)));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(&c, c_dev, sizeof(unsigned long long), cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"c = %llu\\n\", c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-026",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_race cuda_race.cu\n",
        "# nvc++ -Wall -o cuda_race cuda_race.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_race cuda_race.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-027",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_race"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-042",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 5 :  Observe race condition</font>",
        "\n",
        "Execute the above program many times and observe the results; try changing parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-028",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_race 1000 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-043",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "_<font color=\"green\">Answer for trivial work omitted</font>_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-044",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* OpenMP had three basic tools --- critical, atomic and reduction --- to resolve race conditions depending on the situation.\n",
        "* Roughly, CUDA only has an analogue to atomic and does not have critical or reduction.\n",
        "\n",
        "## 12-1. Atomic add",
        "\n",
        "* CUDA has\n",
        "```\n",
        "atomicAdd(T* p, T x);\n",
        "```\n",
        "function for various types of T.  \n",
        "It performs `*p = *p + x` _atomically_, meaning that it is guaranteed that `*p` is not updated between the point `*p` is read and the point `*p` is written.\n",
        "\n",
        "* See [atomicAdd](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomicadd) for reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-045",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 6 :  Use `atomicAdd`</font>",
        "\n",
        "* Change the following program to resolve the race condition using `atomicAdd` and make sure the result always matches the number of threads launched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-029",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_race_atomic_add.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(unsigned long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    *p = *p + 1;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 1000);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  unsigned long long c;\n",
        "  unsigned long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(unsigned long long)));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(&c, c_dev, sizeof(unsigned long long), cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"c = %llu\\n\", c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-046",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* To compile programs using `atomicAdd`, you need to give `--generate-code arch=compute_80,code=sm_80` to `nvcc`\n",
        "* `--generate-code` specifies which GPU architectures/instruction set `nvcc` generates code for, so it might affect generated code in other ways including performance\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-030",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc --generate-code arch=compute_80,code=sm_80 -o cuda_race_atomic_add cuda_race_atomic_add.cu\n",
        "# nvc++ -Wall -gpu=cc80 -o cuda_race_atomic_add cuda_race_atomic_add.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version --cuda-gpu-arch=sm_80 -o cuda_race_atomic_add cuda_race_atomic_add.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-031",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_race_atomic_add 10000 64\n",
        "./cuda_race_atomic_add 100000 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-047",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_race_atomic_add_ans.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "__global__ void cuda_thread_fun(unsigned long long * p, int n) {\n",
        "  int i        = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  if (i < n) {\n",
        "    atomicAdd(p, 1L);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int n               = (argc > 1 ? atoi(argv[1]) : 1000);\n",
        "  int thread_block_sz = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + thread_block_sz - 1) / thread_block_sz;\n",
        "\n",
        "  unsigned long long c;\n",
        "  unsigned long long * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(unsigned long long)));\n",
        "  check_launch_error((cuda_thread_fun<<<n_thread_blocks,thread_block_sz>>>(c_dev, n)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(&c, c_dev, sizeof(unsigned long long), cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"c = %llu\\n\", c);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-048",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc --generate-code arch=compute_80,code=sm_80 -o cuda_race_atomic_add_ans cuda_race_atomic_add_ans.cu\n",
        "# nvc++ -Wall -gpu=cc80 -o cuda_race_atomic_add_ans cuda_race_atomic_add_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version --cuda-gpu-arch=sm_80 -o cuda_race_atomic_add_ans cuda_race_atomic_add_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-049",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_race_atomic_add_ans 10000 64\n",
        "./cuda_race_atomic_add_ans 100000 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-050",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 13. Barrier synchronization of threads",
        "\n",
        "* Recent CUDA has the notion of cooperative groups, with which you can build a barrier synchronization between threads\n",
        "* setup\n",
        "```\n",
        "#include <cooperative_groups.h>\n",
        "namespace cg = cooperative_groups; // save typing\n",
        "```\n",
        "* create data representing a grouup\n",
        "```\n",
        "cg::grid_group g = cg::this_grid(); // all threads\n",
        "```\n",
        "\n",
        "* perform barrier synchronization when necessary (ensure no threads execute `<after>` until all threads finish `<before>`) \n",
        "```\n",
        "  <before>\n",
        "  g.sync();\n",
        "  <after>\n",
        "```\n",
        "\n",
        "* You need to launch such kernels by\n",
        "```\n",
        "void * args[] = { a0, a1, ... };\n",
        "cudaLaunchCooperativeKernel((void *)f, nb, bs, args);\n",
        "```\n",
        "instead of\n",
        "```\n",
        "f<<<nb,bs>>>(a0, a1, ...);\n",
        "```\n",
        "\n",
        "* See [Cooperative Groups](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cooperative-groups) for reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-051",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 7 :  Use barrier synchronization</font>",
        "\n",
        "Change the following program `sum_array()` so that it correctly outputs the sum of the array by implementing reduction on barrier synchronization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-032",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_sum.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "#include <cooperative_groups.h>\n",
        "\n",
        "//using namespace cooperative_groups;\n",
        "// Alternatively use an alias to avoid polluting the namespace with collective algorithms\n",
        "namespace cg = cooperative_groups;\n",
        "\n",
        "__global__ void sum_array(double * c, long n) {\n",
        "  // should return c[0] + c[1] + ... + c[n-1] in c[0]\n",
        "  // you can destroy other elements of the array\n",
        "  cg::grid_group g = cg::this_grid();\n",
        "  unsigned long long i = g.thread_rank();\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  long n                = (argc > 1 ? atoi(argv[1]) : 10000);\n",
        "  int threads_per_block = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + threads_per_block - 1) / threads_per_block;\n",
        "\n",
        "  double * c = (double *)malloc(sizeof(double) * n);\n",
        "  for (long i = 0; i < n; i++) {\n",
        "    c[i] = 1.0;\n",
        "  }\n",
        "  double * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(double) * n));\n",
        "  check_api_error(cudaMemcpy(c_dev, c, sizeof(double) * n, cudaMemcpyHostToDevice));\n",
        "  void * args[2] = { (void *)&c_dev, (void *)&n };\n",
        "  check_api_error(cudaLaunchCooperativeKernel((void*)sum_array,\n",
        "                                              n_thread_blocks,\n",
        "                                              threads_per_block,\n",
        "                                              args));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(c, c_dev, sizeof(double) * n, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"sum = %f\\n\", c[0]);\n",
        "  assert(c[0] == n);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-033",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_sum cuda_sum.cu\n",
        "# nvc++ -Wall -o cuda_sum cuda_sum.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_sum cuda_sum.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-034",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-052",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_sum_ans.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "#include <cooperative_groups.h>\n",
        "\n",
        "//using namespace cooperative_groups;\n",
        "// Alternatively use an alias to avoid polluting the namespace with collective algorithms\n",
        "namespace cg = cooperative_groups;\n",
        "\n",
        "__global__ void sum_array(double * c, long n) {\n",
        "  // should return c[0] + c[1] + ... + c[n-1] in c[0]\n",
        "  // you can destroy other elements of the array\n",
        "  cg::grid_group g = cg::this_grid();\n",
        "  unsigned long long i = g.thread_rank();\n",
        "  unsigned long long h;\n",
        "  for (int m = n; m > 1; m = h) {\n",
        "    h = (m + 1) / 2;\n",
        "    if (i + h < m) {\n",
        "      c[i] += c[i + h];\n",
        "    }\n",
        "    g.sync();\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  long n                = (argc > 1 ? atoi(argv[1]) : 10000);\n",
        "  int threads_per_block = (argc > 2 ? atoi(argv[2]) : 64);\n",
        "  int n_thread_blocks = (n + threads_per_block - 1) / threads_per_block;\n",
        "\n",
        "  double * c = (double *)malloc(sizeof(double) * n);\n",
        "  for (long i = 0; i < n; i++) {\n",
        "    c[i] = 1.0;\n",
        "  }\n",
        "  double * c_dev;\n",
        "  check_api_error(cudaMalloc(&c_dev, sizeof(double) * n));\n",
        "  check_api_error(cudaMemcpy(c_dev, c, sizeof(double) * n, cudaMemcpyHostToDevice));\n",
        "  void * args[2] = { (void *)&c_dev, (void *)&n };\n",
        "  check_api_error(cudaLaunchCooperativeKernel((void*)sum_array,\n",
        "                                              n_thread_blocks,\n",
        "                                              threads_per_block,\n",
        "                                              args));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  check_api_error(cudaMemcpy(c, c_dev, sizeof(double) * n, cudaMemcpyDeviceToHost));\n",
        "  check_api_error(cudaFree(c_dev));\n",
        "  printf(\"sum = %f\\n\", c[0]);\n",
        "  assert(c[0] == n);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-053",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc -o cuda_sum_ans cuda_sum_ans.cu\n",
        "# nvc++ -Wall -o cuda_sum_ans cuda_sum_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_sum_ans cuda_sum_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-054",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_sum_ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-055",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 8 :  Putting them together: calculating an integral</font>",
        "\n",
        "Write a CUDA program that calculates\n",
        "\n",
        "$$ \\int_0^1 \\int_0^1 \\sqrt{1 - x^2 - y^2}\\,dx\\,dy $$\n",
        "\n",
        "* mathematical note: consider the integrand to be zero outside $1 - x^2 - y^2 \\geq 0$\n",
        "\n",
        "* Write a CUDA kernel that computes the integrand on a single point\n",
        "* And launch it with as many threads as the number of points you compute the integrand at\n",
        "* The result should be close to $\\pi/6$ (1/8 of the volume of the unit ball)\n",
        "* Play with the number of infinitesimal intervals for integration and the number of threads so that you can observe a speedup\n",
        "* Measure the time not just for the entire computation, but the time of each step including cudaMalloc, cudaMemcpy to initialize variables on the device, kernel and cudaMemcpy to get the result back\n",
        "* Try atomicAdd as well as reduction \n",
        "* Play with unified memory also"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-035",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile cuda_integral.cu\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-036",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "nvcc -o cuda_integral cuda_integral.cu\n",
        "# nvc++ -Wall -o cuda_integral cuda_integral.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_integral cuda_integral.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-037",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./cuda_integral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-056",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile cuda_integral_ans.cu\n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "\n",
        "#include \"cuda_util.h\"\n",
        "\n",
        "double cur_time() {\n",
        "  struct timespec tp[1];\n",
        "  clock_gettime(CLOCK_REALTIME, tp);\n",
        "  return tp->tv_sec + tp->tv_nsec * 1.0e-9;\n",
        "}\n",
        "\n",
        "__global__ void cuda_thread_fun(int n, double xa, double ya, double dx, double dy, double * sp) {\n",
        "  int i          = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int j          = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "  if (i < n && j < n) {\n",
        "    double x = xa + i * dx;\n",
        "    double y = ya + j * dy;\n",
        "    double z2 = 1 - x * x - y * y;\n",
        "    if (z2 > 0) {\n",
        "      atomicAdd(sp, sqrt(z2) * dx * dy);\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  double xa = 0.0;\n",
        "  double xb = 1.0;\n",
        "  double ya = 0.0;\n",
        "  double yb = 1.0;\n",
        "  int n = 10000;\n",
        "  double dx = (xb - xa) / n;\n",
        "  double dy = (yb - ya) / n;\n",
        "\n",
        "  // thread configuration\n",
        "  int nx                = n;\n",
        "  int ny                = n;\n",
        "  int thread_block_sz_x = (argc > 1 ? atoi(argv[1]) : 8);\n",
        "  int thread_block_sz_y = thread_block_sz_x;\n",
        "  int n_thread_blocks_x = (nx + thread_block_sz_x - 1) / thread_block_sz_x;\n",
        "  int n_thread_blocks_y = (ny + thread_block_sz_y - 1) / thread_block_sz_y;\n",
        "\n",
        "  double s = 0.0;\n",
        "  double * s_dev;\n",
        "  double t0 = cur_time();\n",
        "  check_api_error(cudaMalloc(&s_dev, sizeof(double)));\n",
        "  double t1 = cur_time();\n",
        "  check_api_error(cudaMemcpy(s_dev, &s, sizeof(double), cudaMemcpyHostToDevice));\n",
        "  double t2 = cur_time();\n",
        "  \n",
        "  dim3 nb(n_thread_blocks_x, n_thread_blocks_y);\n",
        "  dim3 tpb(thread_block_sz_x, thread_block_sz_y);\n",
        "  check_launch_error((cuda_thread_fun<<<nb,tpb>>>(n, xa, ya, dx, dy, s_dev)));\n",
        "  check_api_error(cudaDeviceSynchronize());\n",
        "  double t3 = cur_time();\n",
        "  \n",
        "  check_api_error(cudaMemcpy(&s, s_dev, sizeof(double), cudaMemcpyDeviceToHost));\n",
        "  double t4 = cur_time();\n",
        "  \n",
        "  printf(\"ans = %.9f\\n\", s);\n",
        "  printf(\" cudaMalloc  : %f sec\\n\", t1 - t0);\n",
        "  printf(\" host -> dev : %f sec\\n\", t2 - t1);\n",
        "  printf(\" kernel      : %f sec\\n\", t3 - t2);\n",
        "  printf(\" host <- dev : %f sec\\n\", t4 - t3);\n",
        "  printf(\"---------------------------\\n\");\n",
        "  printf(\"total        : %f sec\\n\", t4 - t0);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-057",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "nvcc -o cuda_integral_ans cuda_integral_ans.cu\n",
        "# nvc++ -Wall -o cuda_integral_ans cuda_integral_ans.cu\n",
        "# clang++ -Wall -Wno-unknown-cuda-version -o cuda_integral_ans cuda_integral_ans.cu -L/usr/local/cuda/lib64 -lcudart"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-058",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./cuda_integral_ans"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "SoS",
      "language": "sos",
      "name": "sos"
    },
    "language_info": {
      "codemirror_mode": "sos",
      "file_extension": ".sos",
      "mimetype": "text/x-sos",
      "name": "sos",
      "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
      "pygments_lexer": "sos"
    },
    "sos": {
      "kernels": [
        [
          "Bash",
          "bash",
          "bash",
          "",
          "shell"
        ],
        [
          "C",
          "c_kernel",
          "c",
          "",
          ""
        ],
        [
          "Go",
          "gophernotes",
          "go",
          "",
          ""
        ],
        [
          "Julia 1.10.2",
          "julia-1.10",
          "julia",
          "",
          ""
        ],
        [
          "OCaml default",
          "ocaml-jupyter",
          "OCaml",
          "",
          "text/x-ocaml"
        ],
        [
          "Python 3 (ipykernel)",
          "python3",
          "python3",
          "",
          {
            "name": "ipython",
            "version": 3
          }
        ],
        [
          "Rust",
          "rust",
          "rust",
          "",
          ""
        ]
      ],
      "panel": {
        "displayed": true,
        "height": 0
      },
      "version": "0.23.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}