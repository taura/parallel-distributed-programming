{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-001",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "#  OpenMP for GPU",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-002",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "Enter your name and student ID.\n",
        "\n",
        " * Name:\n",
        " * Student ID:\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-003",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "# 1. OpenMP for GPU",
        "\n",
        "* <a href=\"http://openmp.org/\" target=\"_blank\" rel=\"noopener\">OpenMP</a> is the de fact programming model for multicore environment\n",
        "* More recently, it supports GPU offloading\n",
        "* In this notebook you are going to learn OpenMP for GPU\n",
        "* Consult [the spec](https://www.openmp.org/spec-html/5.0/openmp.html) when necessary\n",
        "* Take a look at [a talk slide OPENMP IN NVIDIA'S HPC by Jeff Larkin](https://openmpcon.org/wp-content/uploads/openmpcon2021-nvidia.pdf)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-004",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 2. Compilers",
        "\n",
        "* [NVIDIA HPC SDK](https://docs.nvidia.com/hpc-sdk/index.html) (`nvc` and `nvc++`) and recent [LLVM](https://llvm.org/) (`clang` and `clang++`) have a decent support of OpenMP for GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-005",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-1. Set up NVIDIA HPC SDK",
        "\n",
        "Execute this before you use NVIDIA HPC SDK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-006",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/22.11/compilers/bin:$PATH\n",
        "#export PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/22.9/compilers/bin:$PATH\n",
        "#export PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/22.7/compilers/bin:$PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-007",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Check if it works (check if full paths of nvc/nvc++ are shown)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-008",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which nvc\n",
        "which nvc++"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-009",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-2. Set up LLVM",
        "\n",
        "Execute this before you use LLVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-010",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "export PATH=/home/share/llvm/bin:$PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-011",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Check if it works (check if full paths of nvc/nvc++ are shown)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-012",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "which clang\n",
        "which clang++"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-013",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Compilers can work at any host, but make sure you are on the GPU host before running GPU programs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-014",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "hostname\n",
        "hostname | grep tauleg || echo \"Oh, you are not on the right host, access https://tauleg000.zapto.org/ instead\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-015",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2-3. Summary of compiler options to compile OpenMP programs for GPU",
        "\n",
        "* `clang`/`clang++` : `-fopenmp -fopenmp-targets=nvptx64` options\n",
        "* `nvc`/`nvc++` : `-mp -target-gpu` option"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-016",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 3. Summary of directives you are going to learn",
        "\n",
        "* [`#pragma omp target`](https://www.openmp.org/spec-html/5.0/openmpsu60.html#x86-2820002.12.5) : offloads the immediately following statement to the device\n",
        "* [`#pragma omp teams`](https://www.openmp.org/spec-html/5.0/openmpse15.html#x57-910002.7) : creates a number of teams (similar to `#pragma omp parallel`)\n",
        "* [`#pragma omp distribute`](https://www.openmp.org/spec-html/5.0/openmpsu43.html#x66-1580002.9.4) : distributes iterations of the immediately following for loop to teams\n",
        "* [`#pragma omp parallel`](https://www.openmp.org/spec-html/5.0/openmpse14.html#x54-800002.6) : creates a number of threads within a team\n",
        "* [`#pragma omp for`](https://www.openmp.org/spec-html/5.0/openmpsu41.html#x64-1290002.9.2) : distributes iterations of the immediately following for loop to threads of a team\n",
        "* [`#pragma omp target data`](https://www.openmp.org/spec-html/5.0/openmpsu57.html#x83-2580002.12.2)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 4. [`#pragma omp target`](https://www.openmp.org/spec-html/5.0/openmpsu60.html) $\\sim$ moving control to a GPU",
        "\n",
        "* <font color=\"blue\">syntax</font>\n",
        "```\n",
        "#pragma omp target\n",
        "    S\n",
        "```\n",
        "executes $S$ on (_offloads_ $S$ to) a device (hopefully a GPU)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-018",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_target.cc\n",
        "#include <stdio.h>\n",
        "int main() {\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "  printf(\"hello from target (hopefully GPU)\\n\");\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-019",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-020",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -fopenmp -fopenmp-targets=nvptx64 omp_target.cc -o omp_target\n",
        "# nvc++ -mp -target=gpu omp_target.cc -o omp_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-021",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* clang complains that CUDA version is too new (newer than the version LLVM supports)\n",
        "* you can suppress it by `-Wno-unknown-cuda-version`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-022",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_target.cc -o omp_target\n",
        "# nvc++ -mp -target=gpu omp_target.cc -o omp_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-023",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-024",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-025",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * while using `target` almost always intends to use a GPU, it can actually run without a GPU (fallback)\n",
        "  * executing the above program results in an identical result whether your machine has a GPU or not\n",
        "  * while good for portability, it may be confusing, so you can force it to run on GPU or signal an error when GPU is not available, by setting environment variable `OMP_TARGET_OFFLOAD=MANDATORY`.  `OMP_TARGET_OFFLOAD=DISABLED` has the opposite effect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-026",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# force it to run on GPU or signal an error\n",
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_target\n",
        "# force it to run on the host even if GPU is available\n",
        "OMP_TARGET_OFFLOAD=DISABLED ./omp_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-027",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 5. [`#pragma omp teams`](https://www.openmp.org/spec-html/5.0/openmpse15.html#x57-910002.7) $\\sim$ creating thread blocks",
        "\n",
        "## 5-1. basics",
        "\n",
        "* <font color=\"blue\">syntax</font>\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    S\n",
        "```\n",
        "creates a number of _teams_ and the master of each team will execute $S$\n",
        "\n",
        "* it is similar to `#pragma omp parallel` in the sense that the effect is to have many threads execute the same statement\n",
        "* you can think of `teams` an extra layer of parallelism outside `parallel` (`parallel` is a construct that creates threads _within_ a team)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-028",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_teams.cc\n",
        "#include <stdio.h>\n",
        "int main() {\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "  printf(\"hello, I am the master of a team\\n\");\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-029",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_teams.cc -o omp_teams\n",
        "# nvc++ -mp -target=gpu omp_teams.cc -o omp_teams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-030",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-031",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_teams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-032",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * `teams` should appear right inside `target`\n",
        "  * as such, `target` and `teams` are often used in the combined form (`#pragma omp target teams`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-033",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 5-2. specifying the number of teams",
        "\n",
        "* you can set the number of teams created by `teams` construct to $x$ either by\n",
        "  * having `num_teams(x)` clause in the `teams` construct\n",
        "  * setting `OMP_NUM_TEAMS=x` environment variable when running the command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-034",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_NUM_TEAMS=3 ./omp_teams\n",
        "OMP_NUM_TEAMS=5 ./omp_teams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-035",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 5-3. getting team ID and the number of teams",
        "\n",
        "* just as `omp_get_thread_num()` and `omp_get_num_threads()` tell you the thread ID and the number of threads of your team, you can get the team ID and the number of teams by\n",
        "  * `omp_get_team_num()`\n",
        "  * `omp_get_num_teams()` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-036",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_team_num.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main() {\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "  printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-037",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_team_num.cc -o omp_team_num\n",
        "# nvc++ -mp -target=gpu omp_team_num.cc -o omp_team_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-038",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-039",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_NUM_TEAMS=5 ./omp_team_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-040",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 6. [`#pragma omp distribute`](https://www.openmp.org/spec-html/5.0/openmpsu43.html#x66-1580002.9.4) $\\sim$ distributing iterations to thread blocks",
        "\n",
        "* <font color=\"blue\">syntax</font>\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    {\n",
        "      ...\n",
        "#pragma omp distribute\n",
        "      for (...) {\n",
        "        ...\n",
        "      }\n",
        "    }\n",
        "```\n",
        "distributes iterations of the for-loop across teams\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-041",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_distribute.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5); i++;\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp distribute\n",
        "    for (int i = 0; i < m; i++) {\n",
        "      printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams());\n",
        "    }\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-042",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_distribute.cc -o omp_distribute\n",
        "# nvc++ -mp -target=gpu omp_distribute.cc -o omp_distribute"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-001",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_NUM_TEAMS=3 ./omp_distribute 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-043",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* execute the following command with different number of teams and the command line (the number of iterations) and make sense of the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-044",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 1 :  Understand teams and distribute</font>",
        "\n",
        "* a small quiz before things get more confusing\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ ./omp_distribute $m$</tt></font>\n",
        "* answer with an expression of $T$ and $m$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-002",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_NUM_TEAMS=3 ./omp_distribute 5 | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-003",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-045",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* execute the following command with different number of teams and the command line (the number of iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-046",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * if there is no statements between `teams` and `distribute` they can be combined into one directive, just as `parallel` and `for` can be combined\n",
        "  * recall that `target` can be combined with `teams`, so you can combine all the three "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-047",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_target_teams_distribute.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5);\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams distribute\n",
        "  for (int i = 0; i < m; i++) {\n",
        "    printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "           i, omp_get_team_num(), omp_get_num_teams());\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-048",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_target_teams_distribute.cc -o omp_target_teams_distribute\n",
        "# nvc++ -mp -target=gpu omp_target_teams_distribute.cc -o omp_target_teams_distribute"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-049",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_NUM_TEAMS=3 ./omp_target_teams_distribute 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-050",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* note:\n",
        "  * you can parallelize a loop with just `teams` and `distribute` without `parallel` and `for` described below\n",
        "  * however, to effectively use GPUs, you need to use `parallel` within each team\n",
        "  * while implementation dependent, you can think of a team as a single thread block, so only using teams, you end up creating many thread blocks each having only a single thread, resulting in very inefficient use of GPUs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-051",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 7. [`#pragma omp parallel`](https://www.openmp.org/spec-html/5.0/openmpse14.html#x54-800002.6) $\\sim$ having threads in a thread block",
        "\n",
        "## 7-1. `parallel` inside `teams`",
        "\n",
        "* syntax:\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    {\n",
        "      ...\n",
        "#pragma omp parallel\n",
        "      S\n",
        "    }\n",
        "```\n",
        "creates a number of thread within each team\n",
        "\n",
        "* recall that you used `parallel` to create threads when executing on CPUs\n",
        "* used inside `teams`, it will create threads within the team, each executing $S$\n",
        "\n",
        "* here is an example that illustrates it\n",
        "<font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_team_parallel</tt></font>\n",
        "creates $T$ teams each of which create $H$ threads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-052",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_parallel.cc\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int n_threads= atoi(getenv(\"OMP_NUM_THREADS\"));\n",
        "  if (n_threads % 32) {\n",
        "    fprintf(stderr, \"OMP_NUM_THREADS (%d) must be a multiple of 32\\n\", n_threads);\n",
        "    exit(1);\n",
        "  }\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp parallel num_threads(n_threads)\n",
        "    printf(\"in parallel: %03d/%03d %03d/%03d\\n\",\n",
        "           omp_get_team_num(), omp_get_num_teams(),\n",
        "           omp_get_thread_num(), omp_get_num_threads());\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-053",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_parallel.cc -o omp_parallel\n",
        "# nvc++ -mp -target=gpu omp_parallel.cc -o omp_parallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-054",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_parallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-055",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "* <font color=\"red\">important remarks on the number of threads you specify in `parallel` directive</font>\n",
        "  * on CPU, the number of threads created by `parallel` could be specified either with `OMP_NUM_THREADS=x` environment variable or `num_threads(x)` in `parallel` directive\n",
        "  * but this seems not possible when executing on GPUs (I don't know whether it is an implementation issue or specification)\n",
        "  * you have to use `num_threads(x)` if you need to set it, just as done above\n",
        "  * or you can just omit it to leave it to the system\n",
        "* also, it seems that with both clang and nvc, <font color=red>_the number of threads must a multiple of 32_</font>\n",
        "  * it does not even signal an error, so you must be careful not to unintentionally specify a wrong number\n",
        "  * this is another reason to leave it to the system unless necessary\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-056",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 2 :  Understand teams and parallel</font>",
        "\n",
        "* a similar quiz about the combination of teams and parallel\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_parallel</tt></font>\n",
        "* answer with an expression of $T$ and $H$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-004",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_parallel | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-005",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-057",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 7-2. `parallel` inside `distribute` inside `teams`",
        "\n",
        "* more typically you call `parallel` inside `distribute` (which is necessarily inside `teams`), as you will be parallelizing loops\n",
        "* there is nothing new syntactically\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-058",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_distribute_parallel.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int n_threads= atoi(getenv(\"OMP_NUM_THREADS\"));\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5); i++;\n",
        "  if (n_threads % 32) {\n",
        "    fprintf(stderr, \"OMP_NUM_THREADS (%d) must be a multiple of 32\\n\", n_threads);\n",
        "    exit(1);\n",
        "  }\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp distribute\n",
        "    for (int i = 0; i < m; i++) {\n",
        "      printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp parallel num_threads(n_threads)\n",
        "      printf(\"in parallel: i=%03d %03d/%03d %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams(),\n",
        "             omp_get_thread_num(), omp_get_num_threads());\n",
        "    }\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-059",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_distribute_parallel.cc -o omp_distribute_parallel\n",
        "# nvc++ -mp -target=gpu omp_distribute_parallel.cc -o omp_distribute_parallel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-060",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_distribute_parallel 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-061",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 3 :  Understand teams, distribute, and parallel</font>",
        "\n",
        "* a similar quiz about the combination of teams, distribute, and parallel\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_distribute_parallel $m$</tt></font>\n",
        "* answer with an expression of $T$, $H$, and $m$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-006",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_distribute_parallel 5 | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-007",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-062",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 8. [`#pragma omp for`](https://www.openmp.org/spec-html/5.0/openmpsu41.html#x64-1290002.9.2) $\\sim$ distributing iterations to threads within a thread block",
        "\n",
        "* syntax:\n",
        "```\n",
        "#pragma omp target\n",
        "#pragma omp teams\n",
        "    ...\n",
        "#pragma omp distribute\n",
        "#pragma omp parallel\n",
        "    ...\n",
        "#pragma omp for\n",
        "for (...) {\n",
        "    ...\n",
        "}  \n",
        "```\n",
        "\n",
        "* used inside `parallel`, it will distribute iterations of the loop to threads\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-063",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_for.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int n_threads= atoi(getenv(\"OMP_NUM_THREADS\"));\n",
        "  int i = 1;\n",
        "  int m = (argc > i ? atoi(argv[i]) : 5); i++;\n",
        "  int n = (argc > i ? atoi(argv[i]) : 6); i++;\n",
        "  if (n_threads % 32) {\n",
        "    fprintf(stderr, \"OMP_NUM_THREADS (%d) must be a multiple of 32\\n\", n_threads);\n",
        "    exit(1);\n",
        "  }\n",
        "  printf(\"hello on host\\n\");\n",
        "#pragma omp target teams\n",
        "  {\n",
        "    printf(\"in teams: %03d/%03d\\n\", omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp distribute\n",
        "    for (int i = 0; i < m; i++) {\n",
        "      printf(\"in distribute: i=%03d executed by %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams());\n",
        "#pragma omp parallel num_threads(n_threads)\n",
        "      printf(\"in parallel: i=%03d %03d/%03d %03d/%03d\\n\",\n",
        "             i, omp_get_team_num(), omp_get_num_teams(),\n",
        "             omp_get_thread_num(), omp_get_num_threads());\n",
        "#pragma omp for\n",
        "      for (int j = 0; j < n; j++) {\n",
        "        printf(\"in for: i=%03d j=%03d executed by %03d/%03d %03d/%03d\\n\",\n",
        "               i, j, omp_get_team_num(), omp_get_num_teams(),\n",
        "               omp_get_thread_num(), omp_get_num_threads());\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  printf(\"back on host\\n\");\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-064",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_for.cc -o omp_for\n",
        "# nvc++ -mp -target=gpu omp_for.cc -o omp_for"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-065",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_for 5 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-066",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 4 :  Understand teams, distribute, parallel, and for</font>",
        "\n",
        "* a similar quiz about the combination of teams, distribute, parallel, and for\n",
        "* reason about which lines are executed by how many threads, and as a result, how many lines are printed when you run the above program with <font color=\"blue\"><tt>OMP_NUM_TEAMS=$T$ OMP_NUM_THREADS=$H$ ./omp_for $m$ $n$</tt></font>\n",
        "* answer with an expression of $T$, $H$, $m$, and $n$\n",
        "* you can easily check your answer by counting the number of lines using `wc` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-008",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "OMP_NUM_TEAMS=3 OMP_NUM_THREADS=32 ./omp_for 5 6 | wc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-009",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-067",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 9. Common combined directives",
        "\n",
        "* anybody who has a right mind will feel sick with the whole series of different directive names that have little or no consistency\n",
        "* each of them is nominally an independent, standalone directive, but many of them are almost always used together in practice\n",
        "* since the purpose is often to execute a loop nest in parallel, most typically they are used in one of the following forms\n",
        "\n",
        "* combine everything \n",
        "```\n",
        "#pragma omp target teams distribute parallel for\n",
        "    for (...) {\n",
        "      ...\n",
        "    }\n",
        "```\n",
        "\n",
        "* parallelize an outer loop with `teams` $+$ `distribute` and an inner loop with `parallel` $+$ `for`\n",
        "\n",
        "```\n",
        "#pragma omp target teams distribute\n",
        "    for (...) {\n",
        "#pragma omp parallel for\n",
        "      for (...) {\n",
        "        ...\n",
        "      }\n",
        "    }  \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-068",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 10. [`#pragma omp target data`](https://www.openmp.org/spec-html/5.0/openmpsu57.html#x83-2580002.12.2) $\\sim$ mapping data between the host CPU and GPU",
        "\n",
        "* in the CUDA programming, the only data transfer that more or less automatically occurs is passing call-by-value arguments (scalars and structures)\n",
        "* arrays and data pointed to by pointers must all be explicitly (1) allocated on GPU memory by `cudaMalloc` and (2) moved between CPU and GPU by `cudaMemcpy`, which quickly becomes tedious and error-prone\n",
        "* what we are conceptually doing when programming in CUDA is to maintain the mapping between data address on CPU and corresponding data address on GPU and synchronize their contents (data in that address) when necessary\n",
        "```\n",
        "a = malloc(...); // data on CPU @ a\n",
        "cudaMalloc(&a_dev, ...); // data on GPU @ a_dev\n",
        "cudaMemcpy(a_dev, a, ...); // move contents a[..] -> a_dev[..]\n",
        "  ...\n",
        "cudaMemcpy(a, a_dev, ...); // move contents a[..] <- a_dev[..]\n",
        "```\n",
        "\n",
        "* `target data` and its `map` clauses make it possible to do this task more easily and declaratively\n",
        "\n",
        "* <font color=\"red\">Warning:</font> I could not (and do not want to) decipher this [super lawyerish spec document about it](https://www.openmp.org/spec-html/5.0/openmpsu109.html#x142-6180002.19.7) to fully understand the behavior of `map` clauses\n",
        "* I am trying to explain it hopefully in a more non-lawyer-friendly and straight-to-the-point way, but part of it is not backed up by the spec document but rather based on actual experiments and my imagination and common sense about what the implementation is doing\n",
        "* when you are not sure, play safe or conduct a similar experiment yourself\n",
        "\n",
        "* <font color=\"blue\">syntax:</font>\n",
        "```\n",
        "#pragma omp target data map(to: ...) map(from: ...) map(tofrom: ...) ...\n",
        "    S\n",
        "```\n",
        "where ... is a variable, array name, or base address + range (e.g., a[0:n])\n",
        "\n",
        "* basically, these clauses say that specified variables, arrays, or address ranges are valid expressions you can get \"expected\" values in the during or after $S$\n",
        "* more specifically, \n",
        "  * those specified in `map(to: ...)` become valid on GPU during $S$\n",
        "  * those specified in `map(from: ...)` become valid on CPU after $S$\n",
        "* to accomplish that, the <font color=\"blue\">_mapping_</font> between CPU address and GPU address are maintained by the runtime system and contents may be moved to or from GPU as necessary\n",
        "  * data specified in `map(to: ...)` may be copied to GPU (CPU -&gt; GPU) before $S$\n",
        "  * data specified in `map(from: ...)` may be copied from GPU (GPU -&gt; CPU) after $S$\n",
        "* `map(tofrom: ...)` has the effect of both; it makes data available to GPU during $S$ and to CPU after $S$\n",
        "\n",
        "* it helps you understand if you think it has two effects\n",
        "  * one is \"transfer data\" that may be accessed from GPU\n",
        "  * the other is \"redirecting pointers\" so that the same expression (e.g., a, a[i], p->x) accesses different locations depending on whether you are on GPU or CPU\n",
        "\n",
        "* you typically use this directive together with `#pragma omp target` and you can in fact specify these clauses in `#pragma omp target`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-069",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-1. local variables and arrays",
        "\n",
        "* local variables and arrays that do not appear in any `map` clause are sent to GPU automatically\n",
        "* so, normally, you don't have to write anything to use (i.e., read) local variables/arrays visible in the scope of `#pragma target` directive\n",
        "* the following program demonstrates that\n",
        "* note that a local arrays (`a`) and a structure (`p`) seems available without any declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-070",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_local.cc\n",
        "#com 2\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "struct point { float x; float y; };\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  point p = { t + 3, t + 4 };\n",
        "#ifpy VER >= 2\n",
        "  printf(\"[host] t @ %p = %f\\n\", &t, t);\n",
        "  printf(\"[host] a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] p @ %p = { %f, %f }\\n\", &p, p.x, p.y);\n",
        "#endifpy\n",
        "  // you do not have to explicitly say anything about t, a, or p.\n",
        "  // they are automatically available on GPU\n",
        "#pragma omp target\n",
        "  {\n",
        "#ifpy VER == 1\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"p = { %f, %f }\\n\", p.x, p.y);\n",
        "#elsepy\n",
        "    printf(\"[dev ] t @ %p = %f\\n\", &t, t);\n",
        "    printf(\"[dev ] a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] p @ %p = { %f, %f }\\n\", &p, p.x, p.y);\n",
        "#endifpy\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-071",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_local.cc -o omp_map_local\n",
        "# nvc++ -mp -target=gpu omp_map_local.cc -o omp_map_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-072",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_local"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-073",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-2. need map(from: $x$) or map(tofrom: $x$) to get the result back",
        "\n",
        "* the following code fails to obtain the result written to variable `t`\n",
        "  * to my surprise, values written to `a` and `p` are available back on CPU\n",
        "  * I didn't try to decipher [the lawyerish spec document](https://www.openmp.org/spec-html/5.0/openmpsu109.html#x142-6180002.19.7) to understand this behavior\n",
        "  * for now, I think it's a safe bet to always specify variables through which you want to obtain results from GPU when you are not sure\n",
        "\n",
        "* you need to specify `map` clause for `t`, either with `map(from: t)` when you don't have to send the value set by CPU to GPU, or with `map(tofrom: t)` when you have to\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-074",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_from.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "struct point { float x; float y; };\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  point p = { t + 3, t + 4 };\n",
        "#pragma omp target \n",
        "  {\n",
        "    t *= 2.0;\n",
        "    for (int i = 0; i < 3; i++) a[i] *= 2.0;\n",
        "    p.x *= 2.0; p.y *= 2.0;\n",
        "  }\n",
        "  printf(\"t = %f\\n\", t);\n",
        "  printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  printf(\"p = { %f, %f }\\n\", p.x, p.y);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-075",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_from.cc -o omp_map_from\n",
        "# nvc++ -mp -target=gpu omp_map_from.cc -o omp_map_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-076",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-077",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 5 :  Use map(from: ..) or map(tofrom: ..) to get the result back</font>",
        "\n",
        "* add an appropriate `map` clause so the CPU can get all the results back\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-010",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile omp_map_from.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "struct point { float x; float y; };\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  point p = { t + 3, t + 4 };\n",
        "#pragma omp target \n",
        "  {\n",
        "    t *= 2.0;\n",
        "    for (int i = 0; i < 3; i++) a[i] *= 2.0;\n",
        "    p.x *= 2.0; p.y *= 2.0;\n",
        "  }\n",
        "  printf(\"t = %f\\n\", t);\n",
        "  printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  printf(\"p = { %f, %f }\\n\", p.x, p.y);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-011",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_from.cc -o omp_map_from\n",
        "# nvc++ -mp -target=gpu omp_map_from.cc -o omp_map_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-012",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./omp_map_from"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-078",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-3. global variables and arrays",
        "\n",
        "* global variables and arrays are similar to local variables and arrays in that they are sent to GPU automatically when they do not appear in any `map` clause \n",
        "* again, the opposite is not true"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-079",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_global.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "struct point { float x; float y; };\n",
        "float t;\n",
        "float a[3];\n",
        "point p;\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  for (int i = 0; i < 3; i++) { a[i] = t + i; }\n",
        "  p.x = t + 3; p.y = t + 4;\n",
        "#ifpy VER >= 2\n",
        "  printf(\"[host] t @ %p = %f\\n\", &t, t);\n",
        "  printf(\"[host] a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] p @ %p = { %f, %f }\\n\", &p, p.x, p.y);\n",
        "#endifpy\n",
        "#pragma omp target\n",
        "  {\n",
        "#ifpy VER == 1\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"p = { %f, %f }\\n\", p.x, p.y);\n",
        "#elsepy\n",
        "    printf(\"[dev ] t @ %p = %f\\n\", &t, t);\n",
        "    printf(\"[dev ] a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] p @ %p = { %f, %f }\\n\", &p, p.x, p.y);\n",
        "#endifpy\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-080",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_global.cc -o omp_map_global\n",
        "# nvc++ -mp -target=gpu omp_map_global.cc -o omp_map_global"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-081",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_global"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-082",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-4. what happens on pointers?",
        "\n",
        "* interestingly, a local pointer pointing to another local variable or an array mapped by a map clause (or a lack thereof) gets automatically \"redirected\" so that it points to the GPU version\n",
        "* in the following program, data access through a pointer `pa` are valid without any map clause, as the data it points to (`a`) are automatically mapped on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-083",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr.cc\n",
        "#com 3\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  float * pa = a;\n",
        "#ifpy VER == 2\n",
        "  printf(\"[host]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "#endifpy\n",
        "#pragma omp target\n",
        "  {\n",
        "#ifpy VER == 1\n",
        "    printf(\" a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "#elifpy VER == 2\n",
        "    printf(\"[dev ]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "#elsepy\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "#endifpy\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-084",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr.cc -o omp_map_ptr\n",
        "# nvc++ -mp -target=gpu omp_map_ptr.cc -o omp_map_ptr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-085",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_ptr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-086",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* it's interesting to see the addresses of these data\n",
        "* the addresses of array `a` are naturally different between CPU and GPU\n",
        "* remarkably, the addresses held in a pointer variable `pa` are _adjusted_ so it now points to the GPU version of `a`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-087",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr_with_addr.cc\n",
        "#com 3\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  float * pa = a;\n",
        "#ifpy VER == 2\n",
        "  printf(\"[host]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "#endifpy\n",
        "#pragma omp target\n",
        "  {\n",
        "#ifpy VER == 1\n",
        "    printf(\" a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "#elifpy VER == 2\n",
        "    printf(\"[dev ]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "#elsepy\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "#endifpy\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-088",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_with_addr.cc -o omp_map_ptr_with_addr\n",
        "# nvc++ -mp -target=gpu omp_map_ptr_with_addr.cc -o omp_map_ptr_with_addr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-089",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_ptr_with_addr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-090",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "* this adjustment happens because `a` is mapped on the GPU as well, due to expressions involving `a`, such as `a[0]`, `a[1]`, etc. appear in the target statement\n",
        "* if you remove the first statement to leave only the expressions involving `pa`, the adjustment does not occur and you get an error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-091",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr_err.cc\n",
        "#com 3\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  float * pa = a;\n",
        "#ifpy VER == 2\n",
        "  printf(\"[host]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "#endifpy\n",
        "#pragma omp target\n",
        "  {\n",
        "#ifpy VER == 1\n",
        "    printf(\" a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "#elifpy VER == 2\n",
        "    printf(\"[dev ]  a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] pa @ %p = { %f, %f, %f }\\n\", pa, pa[0], pa[1], pa[2]);\n",
        "#elsepy\n",
        "    printf(\"pa = { %f, %f, %f }\\n\", pa[0], pa[1], pa[2]);\n",
        "#endifpy\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-092",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_err.cc -o omp_map_ptr_err\n",
        "# nvc++ -mp -target=gpu omp_map_ptr_err.cc -o omp_map_ptr_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-093",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_ptr_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-094",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-5. pointer to heap-allocated data",
        "\n",
        "* it's not that everything is handled so nicely, of course\n",
        "* the most basic situation you need to handle yourself is a pointer to heap-allocated data (by `malloc` or `new`, or anything other than local/global variables/arrays visible and used in `target`, as a matter of fact)\n",
        "* in these cases you need to explicitly specify a pointer and a range you want to make valid on GPU, by a range expression like <font color=\"blue\">_p_[_start_:_end_]</font> or <font color=\"blue\">_p_[_start_:_end_:_stride_]</font>\n",
        "\n",
        "* here is an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-095",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_heap.cc\n",
        "#com 2\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float * a = new float[3];     // heap-allocated data\n",
        "  for (int i = 0; i < 3; i++) { a[i] = t + i; }\n",
        "#ifpy VER == 1\n",
        "#pragma omp target\n",
        "#elsepy\n",
        "#pragma omp target map(to: a[0:3])\n",
        "#endifpy\n",
        "  {\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-096",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_heap.cc -o omp_map_heap\n",
        "# nvc++ -mp -target=gpu omp_map_heap.cc -o omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-097",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-098",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 6 :  Use `map` clause (with a range expression) to make pointer to heap valid</font>",
        "\n",
        "* add an appropriate `map` clause so the GPU can get data in array `a` from CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-013",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile omp_map_heap.cc\n",
        "#com 2\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float * a = new float[3];     // heap-allocated data\n",
        "  for (int i = 0; i < 3; i++) { a[i] = t + i; }\n",
        "#ifpy VER == 1\n",
        "#pragma omp target\n",
        "#elsepy\n",
        "#pragma omp target map(to: a[0:3])\n",
        "#endifpy\n",
        "  {\n",
        "    printf(\"t = %f\\n\", t);\n",
        "    printf(\"a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-014",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_heap.cc -o omp_map_heap\n",
        "# nvc++ -mp -target=gpu omp_map_heap.cc -o omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-015",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./omp_map_heap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-099",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 10-6. a pointer buried in another data",
        "\n",
        "* another situation you need to explicitly handle data mapping is when a pointer is buried in another data structure (e.g., a struct containing a pointer)\n",
        "* such a pointer is not automatically _adjusted_ even if it happens to point to a local variable or an array that will be mapped automatically or by an explicit `map` clause\n",
        "\n",
        "* here is an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-100",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "%%writefile omp_map_ptr_in_data.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "struct cell { float x; float * a; };\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  cell c = { t + 3, a };\n",
        "#ifpy VER >= 2\n",
        "  printf(\"[host]   t @ %p = %f\\n\", &t, t);\n",
        "  printf(\"[host]   a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] c.x @ %p = %f\\n\", &c.x, c.x);\n",
        "  printf(\"[host] c.a @ %p = { %f, %f, %f }\\n\", c.a, c.a[0], c.a[1], c.a[2]);\n",
        "#endifpy\n",
        "#ifpy VER == 1\n",
        "#pragma omp target\n",
        "#elsepy\n",
        "#pragma omp target map(to: c, c.a[0:3])\n",
        "#endifpy\n",
        "  {\n",
        "#ifpy VER == 1\n",
        "    printf(\"  t = %f\\n\", t);\n",
        "    printf(\"  a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"c.x = %f\\n\", c.x);\n",
        "    printf(\"c.a = %p\\n\", c.a);\n",
        "    printf(\"c.a = { %f, %f, %f }\\n\", c.a[0], c.a[1], c.a[2]);\n",
        "#elsepy\n",
        "    printf(\"[dev ]   t @ %p = %f\\n\", &t, t);\n",
        "    printf(\"[dev ]   a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] c.x @ %p = %f\\n\", &c.x, c.x);\n",
        "    printf(\"[dev ] c.a @ %p\\n\", c.a);\n",
        "    printf(\"[dev ] c.a @ %p = { %f, %f, %f }\\n\", c.a, c.a[0], c.a[1], c.a[2]);\n",
        "#endifpy\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-101",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_in_data.cc -o omp_map_ptr_in_data\n",
        "# nvc++ -mp -target=gpu omp_map_ptr_in_data.cc -o omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-102",
          "locked": false,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "./omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-103",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# <font color=\"green\"> Problem 7 :  make pointer in another data structure valid</font>",
        "\n",
        "* specify a map clause to indicate that you want to read `c.a[0:3]` in GPU\n",
        "* <font color=\"red\">if you do that, however, a surprising side effect happens (another thing I couldn't get yet from the spec)</font>\n",
        "* witness by yourself and fix it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-016",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile omp_map_ptr_in_data.cc\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "struct cell { float x; float * a; };\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float t = (argc > i ? atof(argv[i]) : 10.0); i++;\n",
        "  float a[3] = { t, t + 1, t + 2 };\n",
        "  cell c = { t + 3, a };\n",
        "#ifpy VER >= 2\n",
        "  printf(\"[host]   t @ %p = %f\\n\", &t, t);\n",
        "  printf(\"[host]   a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "  printf(\"[host] c.x @ %p = %f\\n\", &c.x, c.x);\n",
        "  printf(\"[host] c.a @ %p = { %f, %f, %f }\\n\", c.a, c.a[0], c.a[1], c.a[2]);\n",
        "#endifpy\n",
        "#ifpy VER == 1\n",
        "#pragma omp target\n",
        "#elsepy\n",
        "#pragma omp target map(to: c, c.a[0:3])\n",
        "#endifpy\n",
        "  {\n",
        "#ifpy VER == 1\n",
        "    printf(\"  t = %f\\n\", t);\n",
        "    printf(\"  a = { %f, %f, %f }\\n\", a[0], a[1], a[2]);\n",
        "    printf(\"c.x = %f\\n\", c.x);\n",
        "    printf(\"c.a = %p\\n\", c.a);\n",
        "    printf(\"c.a = { %f, %f, %f }\\n\", c.a[0], c.a[1], c.a[2]);\n",
        "#elsepy\n",
        "    printf(\"[dev ]   t @ %p = %f\\n\", &t, t);\n",
        "    printf(\"[dev ]   a @ %p = { %f, %f, %f }\\n\", a, a[0], a[1], a[2]);\n",
        "    printf(\"[dev ] c.x @ %p = %f\\n\", &c.x, c.x);\n",
        "    printf(\"[dev ] c.a @ %p\\n\", c.a);\n",
        "    printf(\"[dev ] c.a @ %p = { %f, %f, %f }\\n\", c.a, c.a[0], c.a[1], c.a[2]);\n",
        "#endifpy\n",
        "  }\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-017",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_map_ptr_in_data.cc -o omp_map_ptr_in_data\n",
        "# nvc++ -mp -target=gpu omp_map_ptr_in_data.cc -o omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-018",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "./omp_map_ptr_in_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-104",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# 11. Putting them all together",
        "\n",
        "# <font color=\"green\"> Problem 8 :  get sum of arrays on GPU using OpenMP</font>",
        "\n",
        "* the following is a CPU-only serial code that initializes an array and calculate the sum of elements\n",
        "* all elements are initialized with ones to make the result easy to predict, but of course your code shouldn't exploit that\n",
        "* add appropriate omp directives to calculate the summation on GPU\n",
        "* remember that you are using OpenMP, so many of features you already learned in the CPU context just work (e.g., reduction)\n",
        "* hint:\n",
        "  * you only add a single line to make everything work\n",
        "* change the number of teams (`OMP_NUM_TEAMS`) to see it affects performance \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Python 3 (ipykernel)",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-019",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "%%writefile omp_gpu_sum.cc\n",
        "#com 2\n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "#include <time.h>\n",
        "#include <omp.h>\n",
        "\n",
        "long cur_time() {\n",
        "  struct timespec ts[1];\n",
        "  clock_gettime(CLOCK_REALTIME, ts);\n",
        "  return ts->tv_sec * 1000L * 1000L * 1000L + ts->tv_nsec;\n",
        "}\n",
        "\n",
        "// a small vector-like data structure\n",
        "// vec v(n);\n",
        "// and you can access elements by usual array index\n",
        "// notatin v[i], thanks to operator overloading below\n",
        "struct vec {\n",
        "  long n;\n",
        "  float * a;\n",
        "  vec(long n_) {\n",
        "    n = n_;\n",
        "    a = new float[n];\n",
        "  }\n",
        "  // operator overloading to make v[i] access the element\n",
        "  float& operator[](long i) {\n",
        "    return a[i];\n",
        "  }\n",
        "};\n",
        "\n",
        "// a function that calculates the sum of all elements of v\n",
        "float sum(vec v) {\n",
        "  float s = 0.0;\n",
        "#ifpy VER >= 2\n",
        "#pragma omp target teams distribute parallel for reduction(+:s) map(to: v, v.a[0:v.n]) map(tofrom: s)\n",
        "#endifpy\n",
        "  for (long i = 0; i < v.n; i++) {\n",
        "    s += v[i];\n",
        "  }\n",
        "  return s;\n",
        "}\n",
        "\n",
        "int main(int argc, char ** argv) {\n",
        "  int i = 1;\n",
        "  float m = (argc > i ? atof(argv[i]) : 1000000); i++;\n",
        "  vec v(m);\n",
        "  // init array (on CPU)\n",
        "  for (long i = 0; i < v.n; i++) {\n",
        "    v[i] = 1.0;\n",
        "  }\n",
        "  long t0 = cur_time();\n",
        "  // get sum of the array (you make it happen on GPU)\n",
        "  float s = sum(v);\n",
        "  long t1 = cur_time();\n",
        "  printf(\"pid = %d, answer = %f, took %ld ns\\n\",\n",
        "         getpid(), s, t1 - t0);\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-020",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "clang++ -Wall -Wno-unknown-cuda-version -fopenmp -fopenmp-targets=nvptx64 omp_gpu_sum.cc -o omp_gpu_sum\n",
        "# nvc++ -mp -target=gpu omp_gpu_sum.cc -o omp_gpu_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "kernel": "SoS",
        "nbgrader": {
          "grade": false,
          "grade_id": "c-105",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "\n",
        "* note: in this experiment you don't expect things to run faster on GPU\n",
        "* just make sure things are running on GPU\n",
        "* to this end, play with\n",
        "  * `OMP_TARGET_OFFLOAD=MANDATORY` and `OMP_TARGET_OFFLOAD=DISABLED` and\n",
        "  * `OMP_NUM_TEAMS`\n",
        "to see that performance in fact changes between CPU and GPU and between a large and small number of teams (thread blocks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "kernel": "Bash",
        "nbgrader": {
          "grade": true,
          "grade_id": "p-021",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false,
          "points": 1
        }
      },
      "source": [
        "BEGIN SOLUTION\n",
        "END SOLUTION\n",
        "# make sure you do things on GPU!\n",
        "OMP_TARGET_OFFLOAD=MANDATORY ./omp_gpu_sum\n",
        "# play with a small number of teams\n",
        "OMP_TARGET_OFFLOAD=MANDATORY OMP_NUM_TEAMS=1 ./omp_gpu_sum\n",
        "# CPU\n",
        "OMP_TARGET_OFFLOAD=DISABLED ./omp_gpu_sum"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "SoS",
      "language": "sos",
      "name": "sos"
    },
    "language_info": {
      "codemirror_mode": "sos",
      "file_extension": ".sos",
      "mimetype": "text/x-sos",
      "name": "sos",
      "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
      "pygments_lexer": "sos"
    },
    "sos": {
      "kernels": [
        [
          "Bash",
          "bash",
          "bash",
          "",
          "shell"
        ],
        [
          "C",
          "c_kernel",
          "c",
          "",
          ""
        ],
        [
          "Go",
          "gophernotes",
          "go",
          "",
          ""
        ],
        [
          "Julia 1.10.2",
          "julia-1.10",
          "julia",
          "",
          ""
        ],
        [
          "OCaml default",
          "ocaml-jupyter",
          "OCaml",
          "",
          "text/x-ocaml"
        ],
        [
          "Python 3 (ipykernel)",
          "python3",
          "python3",
          "",
          {
            "name": "ipython",
            "version": 3
          }
        ],
        [
          "Rust",
          "rust",
          "rust",
          "",
          ""
        ]
      ],
      "panel": {
        "displayed": true,
        "height": 0
      },
      "version": "0.23.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}